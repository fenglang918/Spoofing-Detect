#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Complete Spoofing Detection Pipeline with Extended Labels
--------------------------------------------------------
å®Œæ•´çš„ç«¯åˆ°ç«¯è™šå‡æŠ¥å•æ£€æµ‹ç³»ç»Ÿï¼š
â€¢ Step 1: åŸå§‹æ•°æ®åˆå¹¶ (merge_order_trade)
â€¢ Step 2: ç‰¹å¾å·¥ç¨‹å’Œæ‰©å±•æ ‡ç­¾ç”Ÿæˆ (run_etl_from_event) 
â€¢ Step 3: å¤šç§è™šå‡æŠ¥å•æ¨¡å¼è®­ç»ƒå’Œè¯„ä¼°
â€¢ æä¾›ç»Ÿä¸€çš„é…ç½®å’Œæ¶æ„
"""

import argparse
import subprocess
import sys
import time
import pandas as pd
import numpy as np
import lightgbm as lgb
from pathlib import Path
from sklearn.metrics import average_precision_score, roc_auc_score
import json
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

class SpoofingPattern:
    """è™šå‡æŠ¥å•æ¨¡å¼å®šä¹‰"""
    
    def __init__(self, name: str, description: str, rules: dict):
        self.name = name
        self.description = description
        self.rules = rules
    
    def generate_label_logic(self) -> str:
        """ç”Ÿæˆæ ‡ç­¾é€»è¾‘çš„ä»£ç å­—ç¬¦ä¸²"""
        raise NotImplementedError

class QuickCancelImpactPattern(SpoofingPattern):
    """å¿«é€Ÿæ’¤å•å†²å‡»æ¨¡å¼"""
    
    def __init__(self):
        super().__init__(
            name="quick_cancel_impact",
            description="åœ¨æœ€ä½³ä»·ä½çš„å¤§å•å¿«é€Ÿæ’¤å•",
            rules={
                "survival_time_ms": 100,
                "event_type": "æ’¤å•",
                "at_best_price": True,
                "large_order_multiplier": 2.0
            }
        )
    
    def generate_label_logic(self) -> str:
        return f"""
# è§„åˆ™1: å¿«é€Ÿæ’¤å•å†²å‡» - åœ¨æœ€ä½³ä»·ä½çš„å¤§å•å¿«é€Ÿæ’¤å•
conditions_r1 = [
    df_pd['å­˜æ´»æ—¶é—´_ms'] < {self.rules['survival_time_ms']},
    df_pd['äº‹ä»¶ç±»å‹'] == '{self.rules['event_type']}',
    (df_pd['at_bid'] == 1) | (df_pd['at_ask'] == 1),
    df_pd['å§”æ‰˜æ•°é‡'] > df_pd.groupby('ticker')['å§”æ‰˜æ•°é‡'].transform('median') * {self.rules['large_order_multiplier']}
]
"""

class PriceManipulationPattern(SpoofingPattern):
    """ä»·æ ¼æ“çºµæ¨¡å¼"""
    
    def __init__(self):
        super().__init__(
            name="price_manipulation",
            description="æ¿€è¿›å®šä»·ä½†å¿«é€Ÿæ’¤å•",
            rules={
                "survival_time_ms": 500,
                "event_type": "æ’¤å•", 
                "price_aggressiveness_threshold": 2.0,
                "large_order_quantile": 0.75
            }
        )
    
    def generate_label_logic(self) -> str:
        return f"""
# è§„åˆ™2: ä»·æ ¼æ“çºµ - æ¿€è¿›å®šä»·ä½†å¿«é€Ÿæ’¤å•
conditions_r2 = [
    df_pd['å­˜æ´»æ—¶é—´_ms'] < {self.rules['survival_time_ms']},
    df_pd['äº‹ä»¶ç±»å‹'] == '{self.rules['event_type']}',
    np.abs(df_pd['price_aggressiveness']) > {self.rules['price_aggressiveness_threshold']},
    df_pd['å§”æ‰˜æ•°é‡'] > df_pd.groupby('ticker')['å§”æ‰˜æ•°é‡'].transform('quantile', {self.rules['large_order_quantile']})
]
"""

class FakeLiquidityPattern(SpoofingPattern):
    """è™šå‡æµåŠ¨æ€§æ¨¡å¼"""
    
    def __init__(self):
        super().__init__(
            name="fake_liquidity",
            description="æœ€ä½³ä»·ä½å¤§å•å¿«é€Ÿæ’¤å•",
            rules={
                "survival_time_ms": 200,
                "event_type": "æ’¤å•",
                "at_touch": True,
                "large_order_quantile": 0.9
            }
        )
    
    def generate_label_logic(self) -> str:
        return f"""
# è§„åˆ™3: è™šå‡æµåŠ¨æ€§ - æœ€ä½³ä»·ä½å¤§å•å¿«é€Ÿæ’¤å•
conditions_r3 = [
    df_pd['å­˜æ´»æ—¶é—´_ms'] < {self.rules['survival_time_ms']},
    df_pd['äº‹ä»¶ç±»å‹'] == '{self.rules['event_type']}',
    ((df_pd['å§”æ‰˜ä»·æ ¼'] == df_pd['bid1']) | (df_pd['å§”æ‰˜ä»·æ ¼'] == df_pd['ask1'])),
    df_pd['å§”æ‰˜æ•°é‡'] > df_pd.groupby('ticker')['å§”æ‰˜æ•°é‡'].transform('quantile', {self.rules['large_order_quantile']})
]
"""

class LayeringCancelPattern(SpoofingPattern):
    """åˆ†å±‚æ’¤å•æ¨¡å¼"""
    
    def __init__(self):
        super().__init__(
            name="layering_cancel",
            description="åˆ†å±‚æ¨¡å¼ä¸‹çš„å¿«é€Ÿæ’¤å•",
            rules={
                "survival_time_ms": 1000,
                "event_type": "æ’¤å•",
                "requires_layering_score": True
            }
        )
    
    def generate_label_logic(self) -> str:
        return f"""
# è§„åˆ™4: åˆ†å±‚æ’¤å• - åˆ†å±‚æ¨¡å¼ä¸‹çš„å¿«é€Ÿæ’¤å•
conditions_r4 = [
    df_pd['layering_score'] > 0,
    df_pd['å­˜æ´»æ—¶é—´_ms'] < {self.rules['survival_time_ms']},
    df_pd['äº‹ä»¶ç±»å‹'] == '{self.rules['event_type']}'
]
"""

class ActiveHoursSpoofingPattern(SpoofingPattern):
    """æ´»è·ƒæ—¶æ®µå¼‚å¸¸æ¨¡å¼"""
    
    def __init__(self):
        super().__init__(
            name="active_hours_spoofing",
            description="å¼€ç›˜æ”¶ç›˜æ—¶æ®µçš„å¼‚å¸¸è¡Œä¸º",
            rules={
                "survival_time_ms": 50,
                "event_type": "æ’¤å•",
                "active_hours": ["09:30-10:30", "14:00-15:00"],
                "size_multiplier": 1.0
            }
        )
    
    def generate_label_logic(self) -> str:
        return f"""
# è§„åˆ™5: æ´»è·ƒæ—¶æ®µå¼‚å¸¸ - å¼€ç›˜æ”¶ç›˜æ—¶æ®µçš„å¼‚å¸¸è¡Œä¸º
market_active_hours = (
    (df_pd['å§”æ‰˜_datetime'].dt.time >= pd.to_datetime('09:30').time()) &
    (df_pd['å§”æ‰˜_datetime'].dt.time <= pd.to_datetime('10:30').time())
) | (
    (df_pd['å§”æ‰˜_datetime'].dt.time >= pd.to_datetime('14:00').time()) &
    (df_pd['å§”æ‰˜_datetime'].dt.time <= pd.to_datetime('15:00').time())
)
conditions_r5 = [
    df_pd['å­˜æ´»æ—¶é—´_ms'] < {self.rules['survival_time_ms']},
    df_pd['äº‹ä»¶ç±»å‹'] == '{self.rules['event_type']}',
    market_active_hours,
    df_pd['å§”æ‰˜æ•°é‡'] > df_pd.groupby('ticker')['å§”æ‰˜æ•°é‡'].transform('median') * {self.rules['size_multiplier']}
]
"""

class CompleteSpoofingPipeline:
    """å®Œæ•´çš„è™šå‡æŠ¥å•æ£€æµ‹Pipeline"""
    
    def __init__(self):
        self.patterns = [
            QuickCancelImpactPattern(),
            PriceManipulationPattern(),
            FakeLiquidityPattern(),
            LayeringCancelPattern(),
            ActiveHoursSpoofingPattern()
        ]
        
        self.safe_features = [
            # è¡Œæƒ…ç‰¹å¾ï¼ˆå§”æ‰˜æ—¶åˆ»å¯è§‚æµ‹ï¼‰
            "bid1", "ask1", "prev_close", "mid_price", "spread",
            # ä»·æ ¼ç‰¹å¾ï¼ˆå§”æ‰˜æ—¶åˆ»å¯è§‚æµ‹ï¼‰
            "delta_mid", "pct_spread", "price_dev_prevclose",
            # è®¢å•ç‰¹å¾ï¼ˆå§”æ‰˜æ—¶åˆ»å¯è§‚æµ‹ï¼‰
            "is_buy", "log_qty",
            # å†å²ç»Ÿè®¡ç‰¹å¾ï¼ˆåªä½¿ç”¨è¿‡å»çš„ä¿¡æ¯ï¼‰
            "orders_100ms", "cancels_5s",
            # æ—¶é—´ç‰¹å¾
            "time_sin", "time_cos", "in_auction",
            # å¢å¼ºç‰¹å¾ï¼ˆåŸºäºå§”æ‰˜æ—¶åˆ»çš„ä¿¡æ¯ï¼‰
            "book_imbalance", "price_aggressiveness"
        ]
    
    def generate_extended_etl_code(self) -> str:
        """ç”ŸæˆåŒ…å«æ‰©å±•æ ‡ç­¾çš„ETLä»£ç """
        
        # æ”¶é›†æ‰€æœ‰æ¨¡å¼çš„æ ‡ç­¾é€»è¾‘
        pattern_logics = []
        pattern_names = []
        
        for pattern in self.patterns:
            pattern_logics.append(pattern.generate_label_logic())
            pattern_names.append(pattern.name)
        
        etl_code = f'''
def improved_spoofing_rules(df_pd: pd.DataFrame) -> pd.DataFrame:
    """æ”¹è¿›çš„æ¬ºè¯ˆæ£€æµ‹è§„åˆ™ - Extended Labels"""
    labels = {{}}
    try:
        # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
        if 'bid1' not in df_pd.columns and 'ç”³ä¹°ä»·1' in df_pd.columns: 
            df_pd['bid1'] = df_pd['ç”³ä¹°ä»·1']
        if 'ask1' not in df_pd.columns and 'ç”³å–ä»·1' in df_pd.columns: 
            df_pd['ask1'] = df_pd['ç”³å–ä»·1']

        if 'at_bid' not in df_pd.columns and all(c in df_pd.columns for c in ['å§”æ‰˜ä»·æ ¼', 'bid1', 'æ–¹å‘_å§”æ‰˜']):
            df_pd['at_bid'] = ((df_pd['å§”æ‰˜ä»·æ ¼'] == df_pd['bid1']) & (df_pd['æ–¹å‘_å§”æ‰˜'] == 'ä¹°')).astype(int)
        elif 'at_bid' not in df_pd.columns:
            df_pd['at_bid'] = 0

        if 'at_ask' not in df_pd.columns and all(c in df_pd.columns for c in ['å§”æ‰˜ä»·æ ¼', 'ask1', 'æ–¹å‘_å§”æ‰˜']):
            df_pd['at_ask'] = ((df_pd['å§”æ‰˜ä»·æ ¼'] == df_pd['ask1']) & (df_pd['æ–¹å‘_å§”æ‰˜'] == 'å–')).astype(int)
        elif 'at_ask' not in df_pd.columns:
            df_pd['at_ask'] = 0
            
        df_pd['price_aggressiveness'] = df_pd.get('price_aggressiveness', 0.0)
        df_pd['layering_score'] = df_pd.get('layering_score', 0)
        df_pd['å§”æ‰˜_datetime'] = pd.to_datetime(df_pd['å§”æ‰˜_datetime'])
        
        {"".join(pattern_logics)}
        
        # åº”ç”¨å„ä¸ªè§„åˆ™
        {"".join([f"labels['{pattern.name}'] = np.all(conditions_r{i+1}, axis=0).astype(int) if all(col in df_pd.columns for col in ['å­˜æ´»æ—¶é—´_ms', 'äº‹ä»¶ç±»å‹', 'å§”æ‰˜æ•°é‡', 'ticker']) else np.zeros(len(df_pd), dtype=int)" for i, pattern in enumerate(self.patterns)])}
        
        # ç»„åˆæ ‡ç­¾
        labels_df = pd.DataFrame(labels)
        
        # Extended Labels ç»„åˆç­–ç•¥
        df_pd['extended_liberal'] = (
            labels_df[{pattern_names}].sum(axis=1) >= 1
        ).astype(int)  # ä»»æ„ä¸€ç§æ¨¡å¼
        
        df_pd['extended_moderate'] = (
            labels_df[{pattern_names}].sum(axis=1) >= 2  
        ).astype(int)  # è‡³å°‘ä¸¤ç§æ¨¡å¼
        
        df_pd['extended_strict'] = (
            labels_df[{pattern_names}].sum(axis=1) >= 3
        ).astype(int)  # è‡³å°‘ä¸‰ç§æ¨¡å¼
        
        # åŸæœ‰çš„ç»„åˆæ ‡ç­¾ä¿æŒå…¼å®¹
        df_pd['composite_spoofing'] = df_pd['extended_liberal']  # ç­‰åŒäºliberal
        df_pd['conservative_spoofing'] = df_pd['extended_moderate']  # ç­‰åŒäºmoderate
        
        # å°†å„ä¸ªæ¨¡å¼æ ‡ç­¾ä¹ŸåŠ å…¥dataframe
        for col_name in labels_df.columns:
            if col_name not in df_pd.columns:
                df_pd[col_name] = labels_df[col_name]
                
    except Exception as e:
        print(f"  âš ï¸ Error in improved_spoofing_rules: {{e}}")
        default_labels = {pattern_names} + ['extended_liberal', 'extended_moderate', 'extended_strict', 
                          'composite_spoofing', 'conservative_spoofing']
        for label_name in default_labels:
            if label_name not in df_pd.columns:
                df_pd[label_name] = 0
    return df_pd
'''
        return etl_code
    
    def run_merge_step(self, base_data_root: str, tickers: List[str] = None) -> bool:
        """æ­¥éª¤1: è¿è¡Œæ•°æ®åˆå¹¶"""
        print("ğŸ”— Step 1: Merging order and trade data...")
        
        cmd = [
            sys.executable, "scripts/data_process/merge_order_trade.py",
            "--root", base_data_root
        ]
        
        if tickers:
            cmd.extend(["--tickers"] + tickers)
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            print("âœ… Data merge completed successfully")
            return True
        except subprocess.CalledProcessError as e:
            print(f"âŒ Data merge failed: {e.stderr}")
            return False
    
    def run_etl_step(self, event_stream_root: str, tickers: List[str] = None) -> bool:
        """æ­¥éª¤2: è¿è¡ŒETLå¤„ç†å’Œæ‰©å±•æ ‡ç­¾ç”Ÿæˆ"""
        print("ğŸ”§ Step 2: Running ETL with Extended Labels...")
        
        cmd = [
            sys.executable, "scripts/data_process/run_etl_from_event.py",
            "--root", event_stream_root,
            "--enhanced_labels",  # ä½¿ç”¨å¢å¼ºæ ‡ç­¾
            "--backend", "polars",
            "--max_workers", "100"
        ]
        
        if tickers:
            cmd.extend(["--tickers"] + tickers)
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            print("âœ… ETL processing completed successfully")
            return True
        except subprocess.CalledProcessError as e:
            print(f"âŒ ETL processing failed: {e.stderr}")
            return False
    
    def load_data(self, data_root: Path) -> pd.DataFrame:
        """åŠ è½½å’Œåˆå¹¶å¤„ç†åçš„æ•°æ®"""
        print("ğŸ“¥ Step 3: Loading processed data...")
        
        # åŠ è½½ç‰¹å¾
        feat_files = list((data_root / "features_select").glob("X_*.parquet"))
        if not feat_files:
            raise FileNotFoundError("No feature files found. Please run ETL first.")
        
        df_features = pd.concat([pd.read_parquet(f) for f in feat_files], ignore_index=True)
        
        # åŠ è½½æ ‡ç­¾
        label_files = list((data_root / "labels_select").glob("labels_*.parquet"))
        if not label_files:
            raise FileNotFoundError("No label files found. Please run ETL first.")
        
        df_labels = pd.concat([pd.read_parquet(f) for f in label_files], ignore_index=True)
        
        # åˆå¹¶æ•°æ®
        df = df_features.merge(df_labels, on=['è‡ªç„¶æ—¥', 'ticker', 'äº¤æ˜“æ‰€å§”æ‰˜å·'], how='inner')
        
        print(f"  Features: {df_features.shape}")
        print(f"  Labels: {df_labels.shape}")
        print(f"  Merged: {df.shape}")
        
        return df
    
    def analyze_extended_labels(self, df: pd.DataFrame) -> Dict:
        """åˆ†ææ‰©å±•æ ‡ç­¾åˆ†å¸ƒ"""
        print("\nğŸ·ï¸ Extended Labels Analysis:")
        
        results = {}
        
        # åŸå§‹æ ‡ç­¾
        if 'y_label' in df.columns:
            pos_count = int(df['y_label'].sum())  # è½¬æ¢ä¸ºPython int
            pos_rate = float(pos_count / len(df) * 100)  # è½¬æ¢ä¸ºPython float
            results['original'] = {'count': pos_count, 'rate': pos_rate}
            print(f"  {'Original y_label':<25}: {pos_count:>8,} ({pos_rate:>6.3f}%)")
        
        # å„ç§æ¨¡å¼æ ‡ç­¾
        pattern_counts = []
        for pattern in self.patterns:
            if pattern.name in df.columns:
                pos_count = int(df[pattern.name].sum())  # è½¬æ¢ä¸ºPython int
                pos_rate = float(pos_count / len(df) * 100)  # è½¬æ¢ä¸ºPython float
                results[pattern.name] = {
                    'count': pos_count, 
                    'rate': pos_rate,
                    'description': pattern.description
                }
                print(f"  {pattern.name:<25}: {pos_count:>8,} ({pos_rate:>6.3f}%) - {pattern.description}")
                pattern_counts.append(pattern.name)
        
        # ğŸ¯ åŠ¨æ€ç”ŸæˆExtended Labelsç»„åˆæ ‡ç­¾
        if pattern_counts:  # ç¡®ä¿æœ‰å¯ç”¨çš„æ¨¡å¼æ ‡ç­¾
            print(f"\nğŸ“Š Generating Extended Labels (Dynamic):")
            
            # Extended Liberal: ä»»æ„ä¸€ç§æ¨¡å¼å³ä¸ºè™šå‡æŠ¥å•
            pattern_cols = [col for col in pattern_counts if col in df.columns]
            if pattern_cols:
                df['extended_liberal'] = (df[pattern_cols].sum(axis=1) >= 1).astype(int)
                df['extended_moderate'] = (df[pattern_cols].sum(axis=1) >= 2).astype(int)
                df['extended_strict'] = (df[pattern_cols].sum(axis=1) >= 3).astype(int)
                
                # æ‰©å±•ç»„åˆæ ‡ç­¾ç»Ÿè®¡
                for ext_label in ['extended_liberal', 'extended_moderate', 'extended_strict']:
                    pos_count = int(df[ext_label].sum())  # è½¬æ¢ä¸ºPython int
                    pos_rate = float(pos_count / len(df) * 100)  # è½¬æ¢ä¸ºPython float
                    results[ext_label] = {'count': pos_count, 'rate': pos_rate}
                    
                    if ext_label == 'extended_liberal':
                        print(f"  ğŸ¯ {ext_label:<22}: {pos_count:>8,} ({pos_rate:>6.3f}%) [ä»»æ„æ¨¡å¼]")
                    else:
                        print(f"     {ext_label:<22}: {pos_count:>8,} ({pos_rate:>6.3f}%)")
        
        return results
    
    def train_evaluate_model(self, X_train, y_train, X_valid, y_valid, label_name: str) -> Dict:
        """è®­ç»ƒå’Œè¯„ä¼°å•ä¸ªæ¨¡å‹"""
        pos_count = y_train.sum()
        if pos_count == 0:
            print(f"  âš ï¸ {label_name}: No positive samples")
            return None
        
        # æ•°æ®å¹³è¡¡
        pos_indices = y_train[y_train == 1].index
        neg_indices = y_train[y_train == 0].index
        
        balance_ratio = 20
        target_neg_size = min(len(pos_indices) * balance_ratio, len(neg_indices))
        selected_neg_indices = np.random.choice(neg_indices, target_neg_size, replace=False)
        
        selected_indices = np.concatenate([pos_indices, selected_neg_indices])
        X_train_balanced = X_train.loc[selected_indices]
        y_train_balanced = y_train.loc[selected_indices]
        
        # è®­ç»ƒæ¨¡å‹
        model = lgb.LGBMClassifier(
            objective='binary',
            metric='average_precision',
            learning_rate=0.05,
            num_leaves=31,
            max_depth=6,
            n_estimators=1000,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=10,
            reg_lambda=10,
            random_state=42,
            verbose=-1
        )
        
        model.fit(
            X_train_balanced, y_train_balanced,
            eval_set=[(X_valid, y_valid)],
            callbacks=[lgb.early_stopping(100, verbose=False)]
        )
        
        # é¢„æµ‹å’Œè¯„ä¼°
        y_pred_proba = model.predict_proba(X_valid)[:, 1]
        
        metrics = {
            'PR-AUC': average_precision_score(y_valid, y_pred_proba),
            'ROC-AUC': roc_auc_score(y_valid, y_pred_proba),
            'positive_samples': pos_count,
            'positive_rate': pos_count / len(y_train) * 100
        }
        
        # Precision at K
        for k in [0.001, 0.005, 0.01, 0.05]:
            k_int = max(1, int(len(y_valid) * k))
            top_k_idx = y_pred_proba.argsort()[::-1][:k_int]
            prec_k = y_valid.iloc[top_k_idx].mean()
            metrics[f'Precision@{k*100:.1f}%'] = prec_k
        
        print(f"  {label_name:<25}: PR-AUC={metrics['PR-AUC']:.6f}, Precision@0.1%={metrics['Precision@0.1%']:.6f}")
        
        return {
            'model': model,
            'metrics': metrics,
            'predictions': y_pred_proba
        }
    
    def run_training_evaluation(self, df: pd.DataFrame, train_regex: str, valid_regex: str, 
                               results_dir: Path, by_ticker: bool = False) -> Dict:
        """æ­¥éª¤4: è¿è¡Œè®­ç»ƒå’Œè¯„ä¼°"""
        print(f"\nğŸ¯ Step 4: Training and Evaluation ({'by ticker' if by_ticker else 'combined'}):")
        
        # å‡†å¤‡ç‰¹å¾
        leakage_features = [
            "final_survival_time_ms", "total_events", "total_traded_qty",
            "num_trades", "num_cancels", "is_fully_filled", "layering_score"
        ]
        
        df_clean = df.drop(columns=leakage_features, errors='ignore')
        available_features = [f for f in self.safe_features if f in df_clean.columns]
        
        print(f"  Using {len(available_features)} safe features")
        
        # æ•°æ®åˆ‡åˆ†
        train_mask = df_clean["è‡ªç„¶æ—¥"].astype(str).str.contains(train_regex)
        valid_mask = df_clean["è‡ªç„¶æ—¥"].astype(str).str.contains(valid_regex)
        
        df_train = df_clean[train_mask].copy()
        df_valid = df_clean[valid_mask].copy()
        
        print(f"  Training: {len(df_train):,} samples")
        print(f"  Validation: {len(df_valid):,} samples")
        
        if by_ticker:
            return self._train_by_ticker(df_train, df_valid, available_features, results_dir)
        else:
            return self._train_combined(df_train, df_valid, available_features)
    
    def _train_combined(self, df_train: pd.DataFrame, df_valid: pd.DataFrame, available_features: List[str]) -> Dict:
        """ä¼ ç»Ÿçš„åˆå¹¶è®­ç»ƒæ–¹å¼"""
        X_train = df_train[available_features].fillna(0)
        X_valid = df_valid[available_features].fillna(0)
        
        # è®­ç»ƒæ‰€æœ‰æ ‡ç­¾ç­–ç•¥
        all_results = {}
        
        print("  ğŸ“Š Combined Training Results:")
        # åŸå§‹æ ‡ç­¾
        if 'y_label' in df_train.columns:
            result = self.train_evaluate_model(
                X_train, df_train['y_label'], X_valid, df_valid['y_label'], 'Original'
            )
            if result:
                all_results['original'] = result['metrics']
        
        # å„ç§è™šå‡æŠ¥å•æ¨¡å¼
        for pattern in self.patterns:
            if pattern.name in df_train.columns:
                result = self.train_evaluate_model(
                    X_train, df_train[pattern.name], X_valid, df_valid[pattern.name], pattern.name
                )
                if result:
                    all_results[pattern.name] = result['metrics']
        
        # æ‰©å±•æ ‡ç­¾ç»„åˆ
        for ext_label in ['extended_liberal', 'extended_moderate', 'extended_strict']:
            if ext_label in df_train.columns:
                result = self.train_evaluate_model(
                    X_train, df_train[ext_label], X_valid, df_valid[ext_label], ext_label
                )
                if result:
                    all_results[ext_label] = result['metrics']
        
        return all_results
    
    def _train_by_ticker(self, df_train: pd.DataFrame, df_valid: pd.DataFrame, 
                        available_features: List[str], results_dir: Path) -> Dict:
        """æŒ‰è‚¡ç¥¨åˆ†å¼€è®­ç»ƒè¯„ä¼°"""
        all_results = {}
        ticker_results = {}
        
        unique_tickers = sorted(df_train['ticker'].unique())
        print(f"  ğŸ“ˆ Training separately for {len(unique_tickers)} tickers: {unique_tickers}")
        
        # å„ä¸ªè‚¡ç¥¨åˆ†åˆ«è®­ç»ƒ
        for ticker in unique_tickers:
            print(f"\n  ğŸ”¸ Training for {ticker}:")
            
            # åˆ†ç¦»å½“å‰è‚¡ç¥¨æ•°æ®
            train_ticker = df_train[df_train['ticker'] == ticker].copy()
            valid_ticker = df_valid[df_valid['ticker'] == ticker].copy()
            
            if len(train_ticker) == 0 or len(valid_ticker) == 0:
                print(f"    âš ï¸ No data for {ticker}")
                continue
            
            print(f"    Train: {len(train_ticker):,}, Valid: {len(valid_ticker):,}")
            
            X_train_ticker = train_ticker[available_features].fillna(0)
            X_valid_ticker = valid_ticker[available_features].fillna(0)
            
            ticker_results[ticker] = {}
            
            # è®­ç»ƒå„ç§æ ‡ç­¾
            labels_to_train = ['y_label'] + [p.name for p in self.patterns] + \
                            ['extended_liberal', 'extended_moderate', 'extended_strict']
            
            for label_name in labels_to_train:
                if label_name in train_ticker.columns:
                    result = self.train_evaluate_model(
                        X_train_ticker, train_ticker[label_name], 
                        X_valid_ticker, valid_ticker[label_name], 
                        f'{ticker}_{label_name}'
                    )
                    if result:
                        ticker_results[ticker][label_name] = result['metrics']
        
        # è®¡ç®—å¹³å‡æ€§èƒ½å’Œæœ€ä½³è‚¡ç¥¨
        all_results['by_ticker'] = ticker_results
        all_results['ticker_averages'] = self._compute_ticker_averages(ticker_results)
        all_results['best_performers'] = self._find_best_performers(ticker_results)
        
        # ä¿å­˜åˆ†è‚¡ç¥¨ç»“æœ
        self._save_ticker_results(ticker_results, results_dir)
        
        return all_results
    
    def _compute_ticker_averages(self, ticker_results: Dict) -> Dict:
        """è®¡ç®—å„æ ‡ç­¾åœ¨æ‰€æœ‰è‚¡ç¥¨ä¸Šçš„å¹³å‡æ€§èƒ½"""
        averages = {}
        
        # æ”¶é›†æ‰€æœ‰æ ‡ç­¾
        all_labels = set()
        for ticker_data in ticker_results.values():
            all_labels.update(ticker_data.keys())
        
        for label in all_labels:
            label_metrics = {}
            for metric in ['PR-AUC', 'ROC-AUC', 'Precision@0.1%', 'Precision@1.0%']:
                values = []
                for ticker_data in ticker_results.values():
                    if label in ticker_data and metric in ticker_data[label]:
                        values.append(ticker_data[label][metric])
                
                if values:
                    label_metrics[metric] = {
                        'mean': np.mean(values),
                        'std': np.std(values),
                        'min': np.min(values),
                        'max': np.max(values)
                    }
            
            if label_metrics:
                averages[label] = label_metrics
        
        return averages
    
    def _find_best_performers(self, ticker_results: Dict) -> Dict:
        """æ‰¾åˆ°å„æ ‡ç­¾çš„æœ€ä½³è¡¨ç°è‚¡ç¥¨"""
        best_performers = {}
        
        # æ”¶é›†æ‰€æœ‰æ ‡ç­¾
        all_labels = set()
        for ticker_data in ticker_results.values():
            all_labels.update(ticker_data.keys())
        
        for label in all_labels:
            best_performers[label] = {}
            
            for metric in ['PR-AUC', 'ROC-AUC', 'Precision@0.1%']:
                best_score = -1
                best_ticker = None
                
                for ticker, ticker_data in ticker_results.items():
                    if label in ticker_data and metric in ticker_data[label]:
                        score = ticker_data[label][metric]
                        if score > best_score:
                            best_score = score
                            best_ticker = ticker
                
                if best_ticker:
                    best_performers[label][metric] = {
                        'ticker': best_ticker,
                        'score': best_score
                    }
        
        return best_performers
    
    def _save_ticker_results(self, ticker_results: Dict, results_dir: Path):
        """ä¿å­˜åˆ†è‚¡ç¥¨ç»“æœ"""
        # åˆ›å»ºè¯¦ç»†çš„åˆ†è‚¡ç¥¨ç»“æœè¡¨æ ¼
        rows = []
        for ticker, ticker_data in ticker_results.items():
            for label, metrics in ticker_data.items():
                row = {'ticker': ticker, 'label': label}
                row.update(metrics)
                rows.append(row)
        
        if rows:
            ticker_df = pd.DataFrame(rows)
            ticker_df.to_csv(results_dir / "by_ticker_results.csv", index=False, float_format='%.8f')
            
            # åˆ›å»ºé€è§†è¡¨ - æ›´æ˜“è¯»
            for metric in ['PR-AUC', 'ROC-AUC', 'Precision@0.1%']:
                if metric in ticker_df.columns:
                    pivot = ticker_df.pivot(index='ticker', columns='label', values=metric)
                    pivot.to_csv(results_dir / f"by_ticker_{metric.replace('@', '_at_').replace('%', 'pct')}.csv", 
                               float_format='%.6f')
    
    def generate_final_report(self, all_results: Dict, label_analysis: Dict, results_dir: Path, by_ticker: bool = False):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        print("\nğŸ“Š Final Extended Labels Report")
        print("=" * 80)
        
        if by_ticker and 'by_ticker' in all_results:
            self._generate_ticker_report(all_results, results_dir)
        else:
            self._generate_combined_report(all_results, results_dir)
        
        # æ ‡ç­¾åˆ†æ
        with open(results_dir / "extended_labels_analysis.json", 'w') as f:
            json.dump(label_analysis, f, indent=2)
        
        with open(results_dir / "training_results.json", 'w') as f:
            json.dump(all_results, f, indent=2, default=str)
        
        print(f"\nğŸ’¾ All results saved to: {results_dir}")
        
        # ğŸ¯ Extended Liberal Strategy æ€»ç»“
        if 'extended_liberal' in label_analysis:
            liberal_stats = label_analysis['extended_liberal']
            print(f"\nğŸ’¡ Extended Liberal Strategy Summary:")
            print(f"  âœ… è¯†åˆ«äº† {liberal_stats['count']:,} ä¸ªè™šå‡æŠ¥å• ({liberal_stats['rate']:.3f}%)")
            print(f"  âœ… æ¶µç›–äº† {len(self.patterns)} ç§è™šå‡æŠ¥å•æ¨¡å¼")
            print(f"  âœ… ä»»æ„ä¸€ç§æ¨¡å¼å³ä¸ºè™šå‡æŠ¥å• (æœ€å®½æ¾ç­–ç•¥)")
            print(f"  âœ… ä¸ºç›‘ç®¡æä¾›æœ€å…¨é¢çš„è™šå‡æŠ¥å•æ£€æµ‹")
        
        # æ¶æ„æ€»ç»“
        training_mode = "åˆ†è‚¡ç¥¨è®­ç»ƒ" if by_ticker else "åˆå¹¶è®­ç»ƒ"
        print(f"\nğŸ—ï¸ Extended Labels Architecture Summary ({training_mode}):")
        print(f"  âœ… å®šä¹‰äº† {len(self.patterns)} ç§è™šå‡æŠ¥å•æ¨¡å¼")
        print(f"  âœ… ç”Ÿæˆäº†å¤šå±‚æ¬¡çš„æ‰©å±•æ ‡ç­¾ (Liberal/Moderate/Strict)")
        print(f"  âœ… ä¸¥æ ¼æ§åˆ¶ç‰¹å¾æ— æ•°æ®æ³„éœ²")
        print(f"  âœ… æä¾›å®Œæ•´çš„ç«¯åˆ°ç«¯pipeline")
        print(f"  âœ… Extended Liberal = ä¸»è¦å±•ç¤ºç»“æœ")
        if by_ticker:
            print(f"  âœ… åˆ†è‚¡ç¥¨è®­ç»ƒ = æ›´ç²¾å‡†çš„ä¸ªè‚¡æ¨¡å¼è¯†åˆ«")
    
    def _generate_combined_report(self, all_results: Dict, results_dir: Path):
        """ç”Ÿæˆåˆå¹¶è®­ç»ƒçš„æŠ¥å‘Š"""
        # æ€§èƒ½å¯¹æ¯”è¡¨æ ¼
        if all_results:
            comparison_df = pd.DataFrame(all_results).T
            
            key_metrics = ['PR-AUC', 'ROC-AUC', 'Precision@0.1%', 'Precision@1.0%']
            available_metrics = [m for m in key_metrics if m in comparison_df.columns]
            
            print(f"\nğŸ¯ Performance Comparison (Combined Training):")
            print(comparison_df[available_metrics].round(6))
            
            # ğŸ¯ é‡ç‚¹å±•ç¤ºExtended Liberalç»“æœ
            if 'extended_liberal' in comparison_df.index:
                liberal_results = comparison_df.loc['extended_liberal']
                print(f"\nğŸ† Extended Liberal Strategy (ä»»æ„ä¸€ç§æ¨¡å¼å³ä¸ºè™šå‡æŠ¥å•):")
                print(f"  ğŸ“Š PR-AUC: {liberal_results['PR-AUC']:.6f}")
                print(f"  ğŸ“Š ROC-AUC: {liberal_results['ROC-AUC']:.6f}")
                print(f"  ğŸ“Š Precision@0.1%: {liberal_results['Precision@0.1%']:.6f}")
                print(f"  ğŸ“Š Precision@1.0%: {liberal_results['Precision@1.0%']:.6f}")
                
                # ä¸åŸå§‹æ ‡ç­¾å¯¹æ¯”
                if 'original' in comparison_df.index:
                    orig_pr_auc = comparison_df.loc['original', 'PR-AUC']
                    liberal_pr_auc = liberal_results['PR-AUC']
                    improvement = (liberal_pr_auc - orig_pr_auc) / orig_pr_auc * 100
                    print(f"  ğŸ“ˆ vs Original: {improvement:+.1f}% improvement in PR-AUC")
            
            # æœ€ä½³ç­–ç•¥
            if 'PR-AUC' in comparison_df.columns:
                best_strategy = comparison_df['PR-AUC'].idxmax()
                best_score = comparison_df.loc[best_strategy, 'PR-AUC']
                print(f"\nğŸ¥‡ Overall Best Strategy: {best_strategy} (PR-AUC: {best_score:.6f})")
            
            # ä¿å­˜ç»“æœ
            comparison_df.to_csv(results_dir / "extended_labels_performance.csv", float_format='%.8f')
    
    def _generate_ticker_report(self, all_results: Dict, results_dir: Path):
        """ç”Ÿæˆåˆ†è‚¡ç¥¨è®­ç»ƒçš„æŠ¥å‘Š"""
        ticker_averages = all_results.get('ticker_averages', {})
        best_performers = all_results.get('best_performers', {})
        
        print(f"\nğŸ¯ Performance Summary (By Ticker Training):")
        
        # å¹³å‡æ€§èƒ½è¡¨æ ¼
        if ticker_averages:
            avg_data = []
            for label, metrics in ticker_averages.items():
                row = {'Label': label}
                for metric, stats in metrics.items():
                    row[f'{metric}_mean'] = stats['mean']
                    row[f'{metric}_std'] = stats['std']
                avg_data.append(row)
            
            if avg_data:
                avg_df = pd.DataFrame(avg_data)
                key_cols = ['Label'] + [col for col in avg_df.columns if 'PR-AUC' in col or 'Precision@0.1%' in col]
                available_cols = [col for col in key_cols if col in avg_df.columns]
                
                print(avg_df[available_cols].round(6))
                avg_df.to_csv(results_dir / "ticker_averages.csv", index=False, float_format='%.8f')
        
        # ğŸ¯ é‡ç‚¹å±•ç¤ºExtended Liberalå¹³å‡ç»“æœ
        if 'extended_liberal' in ticker_averages:
            liberal_avg = ticker_averages['extended_liberal']
            if 'PR-AUC' in liberal_avg:
                print(f"\nğŸ† Extended Liberal Strategy Average Performance:")
                print(f"  ğŸ“Š PR-AUC: {liberal_avg['PR-AUC']['mean']:.6f} Â± {liberal_avg['PR-AUC']['std']:.6f}")
                print(f"  ğŸ“Š Range: [{liberal_avg['PR-AUC']['min']:.6f}, {liberal_avg['PR-AUC']['max']:.6f}]")
                
                if 'Precision@0.1%' in liberal_avg:
                    print(f"  ğŸ“Š Precision@0.1%: {liberal_avg['Precision@0.1%']['mean']:.6f} Â± {liberal_avg['Precision@0.1%']['std']:.6f}")
        
        # æœ€ä½³è¡¨ç°è‚¡ç¥¨
        if best_performers:
            print(f"\nğŸ¥‡ Best Performing Tickers:")
            for label in ['extended_liberal', 'y_label']:
                if label in best_performers:
                    label_best = best_performers[label]
                    if 'PR-AUC' in label_best:
                        ticker = label_best['PR-AUC']['ticker']
                        score = label_best['PR-AUC']['score']
                        print(f"  {label:<25}: {ticker} (PR-AUC: {score:.6f})")
        
        # æ€§èƒ½åˆ†å¸ƒåˆ†æ
        if 'by_ticker' in all_results:
            self._analyze_ticker_performance_distribution(all_results['by_ticker'], results_dir)
    
    def _analyze_ticker_performance_distribution(self, ticker_results: Dict, results_dir: Path):
        """åˆ†æåˆ†è‚¡ç¥¨æ€§èƒ½åˆ†å¸ƒ"""
        print(f"\nğŸ“ˆ Ticker Performance Distribution Analysis:")
        
        # å…³é”®æ ‡ç­¾åˆ†æ
        key_labels = ['extended_liberal', 'y_label']
        
        for label in key_labels:
            if any(label in ticker_data for ticker_data in ticker_results.values()):
                pr_aucs = []
                tickers = []
                
                for ticker, ticker_data in ticker_results.items():
                    if label in ticker_data and 'PR-AUC' in ticker_data[label]:
                        pr_aucs.append(ticker_data[label]['PR-AUC'])
                        tickers.append(ticker)
                
                if pr_aucs:
                    pr_aucs = np.array(pr_aucs)
                    print(f"\n  {label} PR-AUC Distribution:")
                    print(f"    ğŸ“Š å¹³å‡å€¼: {pr_aucs.mean():.6f}")
                    print(f"    ğŸ“Š æ ‡å‡†å·®: {pr_aucs.std():.6f}")
                    print(f"    ğŸ“Š æœ€å°å€¼: {pr_aucs.min():.6f} ({tickers[np.argmin(pr_aucs)]})")
                    print(f"    ğŸ“Š æœ€å¤§å€¼: {pr_aucs.max():.6f} ({tickers[np.argmax(pr_aucs)]})")
                    print(f"    ğŸ“Š ä¸­ä½æ•°: {np.median(pr_aucs):.6f}")
                    
                    # æ€§èƒ½åˆ†æ¡£
                    high_performers = [(tickers[i], pr_aucs[i]) for i in range(len(pr_aucs)) if pr_aucs[i] > pr_aucs.mean() + pr_aucs.std()]
                    low_performers = [(tickers[i], pr_aucs[i]) for i in range(len(pr_aucs)) if pr_aucs[i] < pr_aucs.mean() - pr_aucs.std()]
                    
                    if high_performers:
                        print(f"    ğŸ† é«˜æ€§èƒ½è‚¡ç¥¨: {high_performers}")
                    if low_performers:
                        print(f"    âš ï¸ ä½æ€§èƒ½è‚¡ç¥¨: {low_performers}")
    
    def run_complete_pipeline(self, base_data_root: str, train_regex: str, valid_regex: str, 
                            tickers: List[str] = None, results_dir: str = None, 
                            skip_merge: bool = False, skip_etl: bool = False, by_ticker: bool = False):
        """è¿è¡Œå®Œæ•´pipeline"""
        print("ğŸš€ Complete Spoofing Detection Pipeline with Extended Labels")
        print("=" * 80)
        
        base_path = Path(base_data_root)
        event_stream_root = base_path.parent / "event_stream"
        data_root = base_path.parent
        
        if results_dir:
            results_dir = Path(results_dir)
        else:
            results_dir = Path("./results")
        results_dir.mkdir(exist_ok=True)
        
        print(f"ğŸ“ Base data: {base_path}")
        print(f"ğŸ“ Event stream: {event_stream_root}")
        print(f"ğŸ“ Results: {results_dir}")
        
        success = True
        
        # æ­¥éª¤1: æ•°æ®åˆå¹¶
        if not skip_merge:
            success = self.run_merge_step(str(base_path), tickers)
            if not success:
                return None
        
        # æ­¥éª¤2: ETLå¤„ç†
        if not skip_etl:
            success = self.run_etl_step(str(event_stream_root), tickers)
            if not success:
                return None
        
        # æ­¥éª¤3: åŠ è½½æ•°æ®
        try:
            df = self.load_data(data_root)
        except FileNotFoundError as e:
            print(f"âŒ {e}")
            return None
        
        # æ­¥éª¤4: åˆ†ææ‰©å±•æ ‡ç­¾
        label_analysis = self.analyze_extended_labels(df)
        
        # æ­¥éª¤5: è®­ç»ƒè¯„ä¼°
        all_results = self.run_training_evaluation(df, train_regex, valid_regex, results_dir, by_ticker)
        
        # æ­¥éª¤6: ç”ŸæˆæŠ¥å‘Š
        self.generate_final_report(all_results, label_analysis, results_dir, by_ticker)
        
        return all_results

def main():
    parser = argparse.ArgumentParser(description="Complete Spoofing Detection Pipeline with Extended Labels")
    parser.add_argument("--base_data_root", required=True, help="åŸå§‹æ•°æ®æ ¹ç›®å½• (base_data)")
    parser.add_argument("--tickers", nargs="*", help="è‚¡ç¥¨åˆ—è¡¨")
    parser.add_argument("--train_regex", default="202503|202504", help="è®­ç»ƒæ•°æ®æ—¥æœŸæ­£åˆ™")
    parser.add_argument("--valid_regex", default="202505", help="éªŒè¯æ•°æ®æ—¥æœŸæ­£åˆ™")
    parser.add_argument("--results_dir", help="ç»“æœä¿å­˜ç›®å½•")
    parser.add_argument("--skip_merge", action="store_true", help="è·³è¿‡æ•°æ®åˆå¹¶æ­¥éª¤")
    parser.add_argument("--skip_etl", action="store_true", help="è·³è¿‡ETLå¤„ç†æ­¥éª¤")
    parser.add_argument("--by_ticker", action="store_true", help="æŒ‰è‚¡ç¥¨åˆ†å¼€è®­ç»ƒè¯„ä¼°")
    
    args = parser.parse_args()
    
    # è¿è¡Œå®Œæ•´pipeline
    pipeline = CompleteSpoofingPipeline()
    results = pipeline.run_complete_pipeline(
        base_data_root=args.base_data_root,
        train_regex=args.train_regex,
        valid_regex=args.valid_regex,
        tickers=args.tickers,
        results_dir=args.results_dir,
        skip_merge=args.skip_merge,
        skip_etl=args.skip_etl,
        by_ticker=args.by_ticker
    )

if __name__ == "__main__":
    main()

"""
ä½¿ç”¨ç¤ºä¾‹ï¼š

# 1. å®Œæ•´è¿è¡Œï¼ˆæ¨èï¼‰
python complete_spoofing_pipeline.py \
  --base_data_root "/obs/users/fenglang/general/Spoofing Detect/data/base_data" \
  --tickers 000989.SZ 300233.SZ --by_ticker

# 2. è·³è¿‡å‰ç½®æ­¥éª¤ï¼Œç›´æ¥è®­ç»ƒ
python complete_spoofing_pipeline.py \
  --base_data_root "/obs/users/fenglang/general/Spoofing Detect/data/base_data" \
  --skip_merge --skip_etl --by_ticker

# 3. åˆå¹¶è®­ç»ƒï¼ˆå¯¹æ¯”ç”¨ï¼‰
python complete_spoofing_pipeline.py \
  --base_data_root "/obs/users/fenglang/general/Spoofing Detect/data/base_data" \
  --skip_merge --skip_etl
""" 