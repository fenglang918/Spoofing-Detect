#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åˆ—å‡ºæ•°æ®ä¸­å¯ç”¨çš„è‚¡ç¥¨ä»£ç 
"""

import argparse
import glob
import os
import pandas as pd

def main():
    parser = argparse.ArgumentParser(description="åˆ—å‡ºæ•°æ®ä¸­å¯ç”¨çš„è‚¡ç¥¨ä»£ç ")
    parser.add_argument("--data_root", required=True, help="æ•°æ®æ ¹ç›®å½•")
    parser.add_argument("--date_regex", default="202503|202504|202505", help="æ—¥æœŸæ­£åˆ™è¡¨è¾¾å¼")
    parser.add_argument("--min_samples", type=int, default=100, help="æœ€å°æ ·æœ¬æ•°é‡")
    parser.add_argument("--show_stats", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯")
    parser.add_argument("--output_file", type=str, default=None, help="è¾“å‡ºåˆ°æ–‡ä»¶")
    
    args = parser.parse_args()
    
    print("ğŸ” æ‰«ææ•°æ®ä¸­çš„è‚¡ç¥¨ä»£ç ...")
    
    # åŠ è½½ç‰¹å¾æ•°æ®
    feat_pats = [
        os.path.join(args.data_root, "features", "X_*.parquet"),
        os.path.join(args.data_root, "features_select", "X_*.parquet")  # å…¼å®¹æ€§
    ]
    
    files = []
    for pat in feat_pats:
        files.extend(sorted(glob.glob(pat)))
    
    if not files:
        print("âŒ æœªæ‰¾åˆ°ç‰¹å¾æ•°æ®æ–‡ä»¶")
        return
    
    print(f"ğŸ“Š åŠ è½½ {len(files)} ä¸ªç‰¹å¾æ–‡ä»¶...")
    
    # åªåŠ è½½tickerå’Œæ—¥æœŸåˆ—ä»¥èŠ‚çœå†…å­˜
    df_list = []
    for file in files:
        try:
            df_temp = pd.read_parquet(file, columns=['è‡ªç„¶æ—¥', 'ticker'])
            df_list.append(df_temp)
        except Exception as e:
            print(f"âš ï¸ è·³è¿‡æ–‡ä»¶ {file}: {e}")
    
    if not df_list:
        print("âŒ æ— æ³•è¯»å–ä»»ä½•æ•°æ®æ–‡ä»¶")
        return
    
    df = pd.concat(df_list, ignore_index=True)
    
    # æŒ‰æ—¥æœŸç­›é€‰
    if args.date_regex:
        date_mask = df["è‡ªç„¶æ—¥"].astype(str).str.contains(args.date_regex)
        df = df[date_mask]
        print(f"ç­›é€‰æ—¥æœŸåæ•°æ®é‡: {len(df):,} æ¡")
    
    # ç»Ÿè®¡è‚¡ç¥¨ä¿¡æ¯
    ticker_stats = df.groupby('ticker').size().sort_values(ascending=False)
    
    # æŒ‰æœ€å°æ ·æœ¬æ•°ç­›é€‰
    if args.min_samples > 0:
        ticker_stats = ticker_stats[ticker_stats >= args.min_samples]
    
    print(f"\nğŸ“‹ å…±æ‰¾åˆ° {len(ticker_stats)} ä¸ªè‚¡ç¥¨ï¼ˆæ ·æœ¬æ•° >= {args.min_samples}ï¼‰")
    
    if args.show_stats:
        print("\nğŸ“Š è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯:")
        print(f"{'è‚¡ç¥¨ä»£ç ':<15} {'æ ·æœ¬æ•°':<10} {'å æ¯”%':<8}")
        print("-" * 35)
        
        total_samples = ticker_stats.sum()
        for ticker, count in ticker_stats.head(20).items():
            percentage = count / total_samples * 100
            print(f"{ticker:<15} {count:<10,} {percentage:<8.2f}")
        
        if len(ticker_stats) > 20:
            print(f"... å’Œå…¶ä»– {len(ticker_stats) - 20} ä¸ªè‚¡ç¥¨")
        
        print(f"\næ€»è®¡: {total_samples:,} æ¡æ ·æœ¬")
        print(f"å¹³å‡æ¯ä¸ªè‚¡ç¥¨: {ticker_stats.mean():.0f} æ¡æ ·æœ¬")
        print(f"ä¸­ä½æ•°: {ticker_stats.median():.0f} æ¡æ ·æœ¬")
    else:
        # ç®€å•åˆ—è¡¨
        print("\nå¯ç”¨è‚¡ç¥¨ä»£ç :")
        for i, ticker in enumerate(ticker_stats.index, 1):
            print(f"{i:3d}. {ticker}")
    
    # è¾“å‡ºåˆ°æ–‡ä»¶
    if args.output_file:
        with open(args.output_file, 'w') as f:
            for ticker in ticker_stats.index:
                f.write(f"{ticker}\n")
        print(f"\nâœ… è‚¡ç¥¨ä»£ç å·²ä¿å­˜åˆ°: {args.output_file}")
    
    # æä¾›ä¸€äº›å»ºè®®
    print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print(f"1. é€‰æ‹©æ ·æœ¬æ•°è¾ƒå¤šçš„è‚¡ç¥¨è¿›è¡Œè®­ç»ƒï¼š")
    top_tickers = ticker_stats.head(5).index.tolist()
    print(f"   --include_tickers {' '.join(top_tickers)}")
    
    print(f"\n2. é™åˆ¶è‚¡ç¥¨æ•°é‡è¿›è¡Œå¿«é€Ÿå®éªŒï¼š")
    print(f"   --max_tickers 10 --ticker_selection_method by_volume")
    
    print(f"\n3. ä»æ–‡ä»¶è¯»å–è‚¡ç¥¨åˆ—è¡¨ï¼š")
    print(f"   --ticker_file tickers.txt")

if __name__ == "__main__":
    main() 