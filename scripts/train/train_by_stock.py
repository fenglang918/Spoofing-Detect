#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Stock-wise LightGBM Training Pipeline for Spoofing Detection
------------------------------------------------------------
ä¸»è¦ç‰¹ç‚¹ï¼š
â€¢ åˆ†è‚¡ç¥¨è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°
â€¢ æ”¯æŒæ¨¡å‹é›†æˆç­–ç•¥
â€¢ å¢å¼ºç‰¹å¾å·¥ç¨‹
â€¢ è¯¦ç»†çš„åˆ†è‚¡ç¥¨æ€§èƒ½åˆ†æ
â€¢ æ”¯æŒè·¨è‚¡ç¥¨æ³›åŒ–æµ‹è¯•
"""

import argparse, glob, os, re, sys, time, warnings
import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.metrics import average_precision_score, classification_report, confusion_matrix, roc_auc_score
from sklearn.model_selection import StratifiedKFold, TimeSeriesSplit
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
import optuna
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
import json
from datetime import datetime

warnings.filterwarnings('ignore')

# ---------- å¯¼å…¥ç°æœ‰çš„å·¥å…·å‡½æ•° --------------------------------
def focal_loss_objective(y_true, y_pred, alpha=0.25, gamma=2.0):
    """
    Focal Loss for LightGBM
    Args:
        y_true: çœŸå®æ ‡ç­¾
        y_pred: é¢„æµ‹æ¦‚ç‡ï¼ˆlogitsï¼‰
        alpha: å¹³è¡¡å› å­ï¼Œç”¨äºå¹³è¡¡æ­£è´Ÿæ ·æœ¬
        gamma: focusingå‚æ•°ï¼Œç”¨äºå‡å°‘æ˜“åˆ†ç±»æ ·æœ¬çš„æƒé‡
    """
    # å°†logitsè½¬æ¢ä¸ºæ¦‚ç‡
    p = 1 / (1 + np.exp(-y_pred))
    
    # è®¡ç®—focal loss
    ce_loss = -y_true * np.log(p + 1e-8) - (1 - y_true) * np.log(1 - p + 1e-8)
    p_t = p * y_true + (1 - p) * (1 - y_true)
    alpha_t = alpha * y_true + (1 - alpha) * (1 - y_true)
    
    focal_weight = alpha_t * (1 - p_t) ** gamma
    focal_loss = focal_weight * ce_loss
    
    # è®¡ç®—æ¢¯åº¦å’Œæµ·å¡çŸ©é˜µ
    grad = focal_weight * (p - y_true)
    hess = focal_weight * p * (1 - p) * (gamma * (y_true - p) + 1)
    
    return grad, hess

def focal_loss_lgb(alpha=0.25, gamma=2.0):
    """è¿”å›LightGBMå¯ç”¨çš„focal lossç›®æ ‡å‡½æ•°"""
    def objective(y_true, y_pred):
        return focal_loss_objective(y_true, y_pred, alpha, gamma)
    return objective

# ---------- Enhanced Feature Engineering --------------------------------
def create_technical_indicators(df):
    """åˆ›å»ºæŠ€æœ¯æŒ‡æ ‡ç‰¹å¾ï¼ˆåŸºäºç°æœ‰åˆ—ï¼‰"""
    features = {}
    
    # ä»·æ ¼æŠ€æœ¯æŒ‡æ ‡
    features['price_volatility'] = df.groupby('ticker')['mid_price'].transform(
        lambda x: x.rolling(100, min_periods=1).std()
    )
    features['price_momentum'] = df.groupby('ticker')['mid_price'].transform(
        lambda x: x.pct_change(5)
    )
    features['relative_spread'] = df['spread'] / df['mid_price']
    features['spread_volatility'] = df.groupby('ticker')['spread'].transform(
        lambda x: x.rolling(50, min_periods=1).std()
    )
    
    # è®¢å•æµæŒ‡æ ‡
    features['order_imbalance'] = (df['bid1'] - df['ask1']) / (df['bid1'] + df['ask1'])
    
    # ä»·æ ¼çº§åˆ«ç‰¹å¾ï¼ˆåŸºäºç°æœ‰çš„ä»·æ ¼ä¿¡æ¯ï¼‰
    # å‡è®¾å§”æ‰˜ä»·æ ¼å¯ä»¥é€šè¿‡mid_priceå’Œdelta_midé‡æ„
    features['at_bid'] = (df['delta_mid'] <= -df['spread']/2).astype(int)
    features['at_ask'] = (df['delta_mid'] >= df['spread']/2).astype(int)
    features['between_quotes'] = ((df['delta_mid'] > -df['spread']/2) & 
                                 (df['delta_mid'] < df['spread']/2)).astype(int)
    
    return pd.DataFrame(features)

def create_statistical_features(df):
    """åˆ›å»ºç»Ÿè®¡ç‰¹å¾"""
    features = {}
    
    # åˆ†ä½æ•°ç‰¹å¾
    for col in ['log_qty', 'spread', 'delta_mid']:
        if col in df.columns:
            # è®¡ç®—åˆ†ä½æ•°rank
            features[f'{col}_rank'] = df.groupby('ticker')[col].transform(
                lambda x: x.rank(pct=True)
            )
            # ç›¸å¯¹äºå¸‚åœºå¹³å‡çš„æ ‡å‡†åŒ–
            features[f'{col}_zscore'] = df.groupby('ticker')[col].transform(
                lambda x: (x - x.mean()) / (x.std() + 1e-8)
            )
    
    # å†å²è¡Œä¸ºç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆï¼Œé¿å…æ—¶é—´åˆ—é—®é¢˜ï¼‰
    features['hist_order_size_mean'] = df.groupby('ticker')['log_qty'].transform(
        lambda x: x.expanding().mean().shift(1)
    )
    features['hist_spread_mean'] = df.groupby('ticker')['spread'].transform(
        lambda x: x.expanding().mean().shift(1)
    )
    
    return pd.DataFrame(features)

def create_interaction_features(df):
    """åˆ›å»ºäº¤äº’ç‰¹å¾"""
    features = {}
    
    # ç¡®ä¿relative_spreadå­˜åœ¨
    if 'relative_spread' not in df.columns:
        df['relative_spread'] = df['spread'] / df['mid_price']
    
    # å…³é”®äº¤äº’
    features['qty_spread_interaction'] = df['log_qty'] * df['relative_spread']
    features['time_qty_interaction'] = df['time_cos'] * df['log_qty']
    features['direction_spread_interaction'] = df['is_buy'] * df['pct_spread']
    
    # ä»·æ ¼-æ—¶é—´äº¤äº’
    features['price_time_interaction'] = df['price_dev_prevclose'] * df['time_sin']
    
    # è®¢å•æ´»åŠ¨äº¤äº’
    features['orders_cancels_ratio'] = df['orders_100ms'] / (df['cancels_5s'] + 1)
    features['activity_spread_interaction'] = df['orders_100ms'] * df['relative_spread']
    
    return pd.DataFrame(features)

def enhance_features(df):
    """å¢å¼ºç‰¹å¾å·¥ç¨‹"""
    print(f"ğŸ”§ Creating enhanced features for {len(df)} samples...")
    
    # è®¡ç®—åŸºç¡€è¡ç”Ÿç‰¹å¾
    if 'relative_spread' not in df.columns:
        df['relative_spread'] = df['spread'] / df['mid_price']
    
    # åˆ›å»ºæŠ€æœ¯æŒ‡æ ‡
    try:
        tech_features = create_technical_indicators(df)
        print(f"Created {len(tech_features.columns)} technical indicators")
    except Exception as e:
        print(f"Warning: Technical indicators failed: {e}")
        tech_features = pd.DataFrame()
    
    # åˆ›å»ºç»Ÿè®¡ç‰¹å¾
    try:
        stat_features = create_statistical_features(df)
        print(f"Created {len(stat_features.columns)} statistical features")
    except Exception as e:
        print(f"Warning: Statistical features failed: {e}")
        stat_features = pd.DataFrame()
    
    # åˆ›å»ºäº¤äº’ç‰¹å¾
    try:
        interaction_features = create_interaction_features(df)
        print(f"Created {len(interaction_features.columns)} interaction features")
    except Exception as e:
        print(f"Warning: Interaction features failed: {e}")
        interaction_features = pd.DataFrame()
    
    # åˆå¹¶æ‰€æœ‰ç‰¹å¾
    feature_dfs = [df]
    if not tech_features.empty:
        tech_features = tech_features.loc[:, ~tech_features.columns.isin(df.columns)]
        if not tech_features.empty:
            feature_dfs.append(tech_features)
    if not stat_features.empty:
        stat_features = stat_features.loc[:, ~stat_features.columns.isin(df.columns)]
        if not stat_features.empty:
            feature_dfs.append(stat_features)
    if not interaction_features.empty:
        existing_cols = df.columns.tolist()
        if len(feature_dfs) > 1:
            for feat_df in feature_dfs[1:]:
                existing_cols.extend(feat_df.columns.tolist())
        interaction_features = interaction_features.loc[:, ~interaction_features.columns.isin(existing_cols)]
        if not interaction_features.empty:
            feature_dfs.append(interaction_features)
    
    enhanced_df = pd.concat(feature_dfs, axis=1)
    
    # æœ€ç»ˆæ£€æŸ¥ï¼šç§»é™¤ä»»ä½•é‡å¤çš„åˆ—
    enhanced_df = enhanced_df.loc[:, ~enhanced_df.columns.duplicated()]
    
    # å¤„ç†æ— ç©·å€¼å’Œç¼ºå¤±å€¼
    enhanced_df = enhanced_df.replace([np.inf, -np.inf], np.nan)
    enhanced_df = enhanced_df.fillna(0)
    
    return enhanced_df

def advanced_sampling(X, y, method='undersample', sampling_strategy='auto'):
    """é«˜çº§é‡‡æ ·ç­–ç•¥"""
    if method == 'none':
        return X, y
    
    print(f"Before sampling: {X.shape[0]} samples, {y.sum()} positive ({y.mean():.3%})")
    
    if method == 'undersample':
        # ç®€å•ä¸‹é‡‡æ ·åˆ°1:10æ¯”ä¾‹
        pos_indices = np.where(y == 1)[0]
        neg_indices = np.where(y == 0)[0]
        
        n_pos = len(pos_indices)
        n_neg_target = min(n_pos * 10, len(neg_indices))  # 1:10æ¯”ä¾‹
        
        if n_neg_target < len(neg_indices):
            selected_neg = np.random.choice(neg_indices, n_neg_target, replace=False)
            selected_indices = np.concatenate([pos_indices, selected_neg])
            X_resampled = X.iloc[selected_indices]
            y_resampled = y.iloc[selected_indices]
        else:
            X_resampled, y_resampled = X, y
    
    elif method == 'stratified_undersample':
        # åˆ†å±‚ä¸‹é‡‡æ ·ï¼ˆå¦‚æœæœ‰tickerä¿¡æ¯ï¼‰
        if hasattr(X, 'ticker') or 'ticker' in X.columns:
            X_resampled_list = []
            y_resampled_list = []
            
            for ticker in X['ticker'].unique():
                ticker_mask = X['ticker'] == ticker
                X_ticker = X[ticker_mask]
                y_ticker = y[ticker_mask]
                
                if y_ticker.sum() > 0:  # åªå¯¹æœ‰æ­£æ ·æœ¬çš„è‚¡ç¥¨è¿›è¡Œé‡‡æ ·
                    X_ticker_sampled, y_ticker_sampled = advanced_sampling(
                        X_ticker, y_ticker, method='undersample'
                    )
                    X_resampled_list.append(X_ticker_sampled)
                    y_resampled_list.append(y_ticker_sampled)
            
            if X_resampled_list:
                X_resampled = pd.concat(X_resampled_list, ignore_index=True)
                y_resampled = pd.concat(y_resampled_list, ignore_index=True)
            else:
                X_resampled, y_resampled = X, y
        else:
            # å›é€€åˆ°æ™®é€šä¸‹é‡‡æ ·
            X_resampled, y_resampled = advanced_sampling(X, y, method='undersample')
    
    else:
        X_resampled, y_resampled = X, y
    
    print(f"After sampling: {X_resampled.shape[0]} samples, {y_resampled.sum()} positive ({y_resampled.mean():.3%})")
    return X_resampled, y_resampled

class EnsembleClassifier:
    """é›†æˆåˆ†ç±»å™¨"""
    def __init__(self, models=None):
        self.models = models or ['lgb', 'xgb', 'rf']
        self.fitted_models = {}
        self.weights = None
    
    def fit(self, X, y, X_val=None, y_val=None):
        """è®­ç»ƒæ‰€æœ‰å­æ¨¡å‹"""
        print("ğŸ”§ Training ensemble models...")
        
        # LightGBM
        if 'lgb' in self.models:
            lgb_model = lgb.LGBMClassifier(
                objective='binary',
                metric='average_precision',
                learning_rate=0.03,
                num_leaves=31,
                max_depth=6,
                n_estimators=1000,
                subsample=0.8,
                colsample_bytree=0.8,
                reg_alpha=10,
                reg_lambda=10,
                random_state=42,
                verbose=-1
            )
            
            if X_val is not None and y_val is not None:
                try:
                    lgb_model.fit(
                        X, y,
                        eval_set=[(X_val, y_val)],
                        early_stopping_rounds=100,
                        verbose=False
                    )
                except TypeError:
                    from lightgbm import early_stopping
                    lgb_model.fit(
                        X, y,
                        eval_set=[(X_val, y_val)],
                        callbacks=[early_stopping(100)]
                    )
            else:
                lgb_model.fit(X, y)
            
            self.fitted_models['lgb'] = lgb_model
            print("âœ… LightGBM trained")
        
        # XGBoost
        if 'xgb' in self.models:
            xgb_model = XGBClassifier(
                learning_rate=0.03,
                max_depth=6,
                n_estimators=1000,
                subsample=0.8,
                colsample_bytree=0.8,
                reg_alpha=10,
                reg_lambda=10,
                random_state=42,
                eval_metric='aucpr',
                verbosity=0
            )
            
            if X_val is not None and y_val is not None:
                xgb_model.fit(
                    X, y,
                    eval_set=[(X_val, y_val)],
                    early_stopping_rounds=100,
                    verbose=False
                )
            else:
                xgb_model.fit(X, y)
            
            self.fitted_models['xgb'] = xgb_model
            print("âœ… XGBoost trained")
        
        # Random Forest
        if 'rf' in self.models:
            rf_model = RandomForestClassifier(
                n_estimators=200,
                max_depth=10,
                min_samples_split=20,
                min_samples_leaf=10,
                random_state=42,
                n_jobs=-1
            )
            rf_model.fit(X, y)
            self.fitted_models['rf'] = rf_model
            print("âœ… Random Forest trained")
        
        # è®¡ç®—æƒé‡
        if X_val is not None and y_val is not None:
            self._compute_weights(X_val, y_val)
    
    def _compute_weights(self, X_val, y_val):
        """åŸºäºéªŒè¯é›†è®¡ç®—æ¨¡å‹æƒé‡"""
        scores = {}
        for name, model in self.fitted_models.items():
            y_pred = model.predict_proba(X_val)[:, 1]
            scores[name] = average_precision_score(y_val, y_pred)
        
        total_score = sum(scores.values())
        self.weights = {name: score/total_score for name, score in scores.items()}
        print(f"Model weights: {self.weights}")
    
    def predict_proba(self, X):
        """é›†æˆé¢„æµ‹"""
        if not self.fitted_models:
            raise ValueError("No models have been fitted")
        
        predictions = []
        weights = []
        
        for name, model in self.fitted_models.items():
            pred = model.predict_proba(X)[:, 1]
            predictions.append(pred)
            weights.append(self.weights.get(name, 1.0) if self.weights else 1.0)
        
        # åŠ æƒå¹³å‡
        predictions = np.array(predictions)
        weights = np.array(weights)
        weights = weights / weights.sum()
        
        ensemble_pred = np.average(predictions, axis=0, weights=weights)
        
        # è¿”å›æ ¼å¼ä¸sklearnå…¼å®¹
        return np.column_stack([1 - ensemble_pred, ensemble_pred])

def comprehensive_evaluation(y_true, y_pred_proba, y_pred_binary=None):
    """ç»¼åˆè¯„ä¼°"""
    if y_pred_binary is None:
        y_pred_binary = (y_pred_proba > 0.5).astype(int)
    
    # åŸºç¡€æŒ‡æ ‡
    pr_auc = average_precision_score(y_true, y_pred_proba)
    roc_auc = roc_auc_score(y_true, y_pred_proba)
    
    metrics = {
        'PR-AUC': pr_auc,
        'ROC-AUC': roc_auc
    }
    
    # Precision@K
    total_positive = y_true.sum()
    n_samples = len(y_true)
    
    for k in [0.001, 0.005, 0.01, 0.02, 0.05, 0.1]:
        k_samples = max(1, int(n_samples * k))
        top_k_indices = np.argsort(y_pred_proba)[::-1][:k_samples]
        
        precision_at_k = y_true.iloc[top_k_indices].mean() if hasattr(y_true, 'iloc') else y_true[top_k_indices].mean()
        theoretical_max = min(total_positive / k_samples, 1.0)
        achievement_rate = precision_at_k / theoretical_max if theoretical_max > 0 else 0
        
        metrics[f'Precision@{k*100:.1f}%'] = precision_at_k
        metrics[f'Precision@{k*100:.1f}%_max'] = theoretical_max
        metrics[f'Precision@{k*100:.1f}%_achievement'] = achievement_rate
    
    return metrics

def train_stock_model(df_stock, feature_cols, args, stock_name):
    """ä¸ºå•åªè‚¡ç¥¨è®­ç»ƒæ¨¡å‹"""
    print(f"\nğŸ“ˆ Training model for {stock_name}...")
    
    # åˆ†å‰²æ•°æ®
    train_mask = df_stock["è‡ªç„¶æ—¥"].astype(str).str.contains(args.train_regex)
    valid_mask = df_stock["è‡ªç„¶æ—¥"].astype(str).str.contains(args.valid_regex)
    
    df_train = df_stock[train_mask].copy()
    df_valid = df_stock[valid_mask].copy()
    
    if len(df_train) == 0 or len(df_valid) == 0:
        print(f"âŒ {stock_name}: Insufficient data (train={len(df_train)}, valid={len(df_valid)})")
        return None
    
    if df_train['y_label'].sum() == 0:
        print(f"âŒ {stock_name}: No positive samples in training data")
        return None
    
    print(f"   Training: {len(df_train):,}, Validation: {len(df_valid):,}")
    print(f"   Train positive: {df_train['y_label'].sum()}/{len(df_train)} ({df_train['y_label'].mean():.3%})")
    print(f"   Valid positive: {df_valid['y_label'].sum()}/{len(df_valid)} ({df_valid['y_label'].mean():.3%})")
    
    # å¢å¼ºç‰¹å¾å·¥ç¨‹
    df_train = enhance_features(df_train)
    df_valid = enhance_features(df_valid)
    
    # ç‰¹å¾é€‰æ‹©
    available_features = [col for col in feature_cols if col in df_train.columns]
    if len(available_features) < len(feature_cols):
        missing = [col for col in feature_cols if col not in df_train.columns]
        print(f"   âš ï¸ Missing {len(missing)} features: {missing[:3]}...")
    
    X_tr = df_train[available_features].fillna(0)
    y_tr = df_train["y_label"]
    X_va = df_valid[available_features].fillna(0)
    y_va = df_valid["y_label"]
    
    # é‡‡æ ·
    if args.sampling_method != "none":
        X_tr, y_tr = advanced_sampling(X_tr, y_tr, method=args.sampling_method)
    
    # è®­ç»ƒæ¨¡å‹
    start_time = time.time()
    
    if args.use_ensemble:
        model = EnsembleClassifier()
        model.fit(X_tr, y_tr, X_va, y_va)
    else:
        # å•æ¨¡å‹
        base_params = {
            'objective': 'binary',
            'metric': 'average_precision',
            'learning_rate': 0.03,
            'num_leaves': 31,
            'max_depth': 6,
            'n_estimators': 1000,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'reg_alpha': 10,
            'reg_lambda': 10,
            'random_state': 42,
            'verbose': -1
        }
        
        if args.use_focal_loss:
            base_params.update({
                'objective': focal_loss_lgb(args.focal_alpha, args.focal_gamma),
                'metric': 'None'
            })
            model = lgb.LGBMClassifier(**base_params)
            model.n_estimators = 500
            model.fit(X_tr, y_tr)
        elif args.use_class_weight:
            neg_count = (y_tr == 0).sum()
            pos_count = (y_tr == 1).sum()
            
            if args.class_weight_ratio is not None:
                scale_pos_weight = args.class_weight_ratio
            else:
                scale_pos_weight = neg_count / pos_count
            
            base_params['scale_pos_weight'] = scale_pos_weight
            model = lgb.LGBMClassifier(**base_params)
        else:
            model = lgb.LGBMClassifier(**base_params)
        
        # è®­ç»ƒ
        if not args.use_focal_loss:
            try:
                model.fit(
                    X_tr, y_tr,
                    eval_set=[(X_va, y_va)],
                    early_stopping_rounds=100,
                    verbose=False
                )
            except TypeError:
                from lightgbm import early_stopping
                model.fit(
                    X_tr, y_tr,
                    eval_set=[(X_va, y_va)],
                    callbacks=[early_stopping(100)]
                )
    
    training_time = time.time() - start_time
    
    # é¢„æµ‹
    if args.use_focal_loss and not args.use_ensemble:
        y_pred_proba = model.predict(X_va)
        y_pred_proba = 1 / (1 + np.exp(-y_pred_proba))
    else:
        y_pred_proba = model.predict_proba(X_va)[:, 1]
    
    # è¯„ä¼°
    metrics = comprehensive_evaluation(y_va, y_pred_proba)
    
    result = {
        'stock': stock_name,
        'model': model,
        'features': available_features,
        'training_time': training_time,
        'train_samples': len(y_tr),
        'valid_samples': len(y_va),
        'train_positive': int(y_tr.sum()),
        'valid_positive': int(y_va.sum()),
        'metrics': metrics,
        'y_true': y_va,
        'y_pred_proba': y_pred_proba
    }
    
    print(f"   âœ… {stock_name}: PR-AUC={metrics['PR-AUC']:.4f}, P@0.1%={metrics.get('Precision@0.1%', 0):.4f}, Time={training_time:.1f}s")
    
    return result

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_root", required=True)
    parser.add_argument("--train_regex", default="202503|202504")
    parser.add_argument("--valid_regex", default="202505")
    parser.add_argument("--sampling_method", choices=["none", "undersample", "stratified_undersample"], 
                       default="undersample", help="é‡‡æ ·æ–¹æ³•")
    parser.add_argument("--use_ensemble", action="store_true", help="ä½¿ç”¨æ¨¡å‹é›†æˆ")
    parser.add_argument("--use_enhanced_labels", action="store_true", 
                       help="ä½¿ç”¨å¢å¼ºæ ‡ç­¾è€Œä¸æ˜¯åŸå§‹y_label")
    parser.add_argument("--label_type", choices=["composite_spoofing", "conservative_spoofing"], 
                       default="composite_spoofing", help="ä½¿ç”¨å“ªç§å¢å¼ºæ ‡ç­¾ç±»å‹")
    parser.add_argument("--use_focal_loss", action="store_true", help="ä½¿ç”¨Focal Losså¤„ç†ä¸å¹³è¡¡æ•°æ®")
    parser.add_argument("--focal_alpha", type=float, default=0.25, help="Focal Loss alphaå‚æ•°")
    parser.add_argument("--focal_gamma", type=float, default=2.0, help="Focal Loss gammaå‚æ•°")
    parser.add_argument("--use_class_weight", action="store_true", help="ä½¿ç”¨ç±»åˆ«æƒé‡å¤„ç†ä¸å¹³è¡¡æ•°æ®")
    parser.add_argument("--class_weight_ratio", type=float, default=None, help="æ­£æ ·æœ¬æƒé‡æ¯”ä¾‹")
    parser.add_argument("--min_samples", type=int, default=1000, help="è‚¡ç¥¨æœ€å°æ ·æœ¬æ•°")
    parser.add_argument("--min_positive", type=int, default=10, help="è‚¡ç¥¨æœ€å°æ­£æ ·æœ¬æ•°")
    parser.add_argument("--eval_output_dir", type=str, default=None, 
                       help="è¯„ä¼°ç»“æœä¿å­˜ç›®å½•ï¼Œé»˜è®¤ä¸º results/stock_wise_results")
    
    args = parser.parse_args()
    
    t0 = time.time()
    print("ğŸ” Loading and preparing data...")
    
    # Load data
    feat_pats = [os.path.join(args.data_root, "features", "X_*.parquet")]
    lab_pats = [os.path.join(args.data_root, "labels", "labels_*.parquet")]
    
    # å¦‚æœæ–°è·¯å¾„ä¸å­˜åœ¨ï¼Œå›é€€åˆ°æ—§è·¯å¾„
    if not glob.glob(feat_pats[0]):
        print("âš ï¸ New architecture paths not found, trying legacy paths...")
        feat_pats = [os.path.join(args.data_root, "features_select", "X_*.parquet")]
        lab_pats = [os.path.join(args.data_root, "labels_select", "labels_*.parquet")]
    
    # åŠ è½½ç‰¹å¾æ•°æ®
    files = []
    for pat in feat_pats:
        files.extend(sorted(glob.glob(pat)))
    
    if not files:
        print(f"âŒ No feature files found.")
        return
    
    print(f"ğŸ“Š Loading features from {len(files)} files...")
    df_feat = pd.concat([pd.read_parquet(f) for f in files], ignore_index=True)
    
    # åŠ è½½æ ‡ç­¾æ•°æ®
    files = []
    for pat in lab_pats:
        files.extend(sorted(glob.glob(pat)))
    
    if not files:
        enhanced_lab_pat = os.path.join(args.data_root, "labels_enhanced", "labels_*.parquet")
        files.extend(sorted(glob.glob(enhanced_lab_pat)))
    
    if not files:
        print(f"âŒ No label files found.")
        return
    
    print(f"ğŸ“Š Loading labels from {len(files)} files...")
    df_lab = pd.concat([pd.read_parquet(f) for f in files], ignore_index=True)
    
    # æ£€æŸ¥å¢å¼ºæ ‡ç­¾
    if args.use_enhanced_labels:
        if args.label_type not in df_lab.columns:
            print(f"âŒ Enhanced label '{args.label_type}' not found in labels.")
            return
        print(f"âœ… Using enhanced label: {args.label_type}")
    
    # åˆå¹¶æ•°æ®
    df = df_feat.merge(df_lab, on=["è‡ªç„¶æ—¥", "ticker", "äº¤æ˜“æ‰€å§”æ‰˜å·"], how="inner")
    print(f"Merged data shape: {df.shape}")
    
    # è®¾ç½®ç›®æ ‡å˜é‡
    if args.use_enhanced_labels:
        df['y_label'] = df[args.label_type]
    
    # è·å–ç‰¹å¾åˆ—
    leakage_cols = [
        "å­˜æ´»æ—¶é—´_ms", "äº‹ä»¶_datetime", "æˆäº¤ä»·æ ¼", "æˆäº¤æ•°é‡", "äº‹ä»¶ç±»å‹",
        "is_cancel_event", "is_trade_event",
        "flag_R1", "flag_R2", "enhanced_spoofing_liberal", 
        "enhanced_spoofing_moderate", "enhanced_spoofing_strict"
    ]
    
    id_cols = ["è‡ªç„¶æ—¥", "ticker", "äº¤æ˜“æ‰€å§”æ‰˜å·", "y_label"]
    exclude_cols = id_cols + leakage_cols
    feature_cols = [col for col in df.columns if col not in exclude_cols]
    
    # ç§»é™¤éæ•°å€¼åˆ—
    non_numeric_cols = []
    for col in feature_cols:
        dtype = df[col].dtype
        if dtype == 'object' or 'datetime' in str(dtype):
            non_numeric_cols.append(col)
    
    feature_cols = [col for col in feature_cols if col not in non_numeric_cols]
    print(f"Using {len(feature_cols)} features")
    
    # æŒ‰è‚¡ç¥¨åˆ†ç»„å¤„ç†
    print(f"\nğŸ“ˆ Analyzing stocks...")
    stock_stats = df.groupby('ticker').agg({
        'y_label': ['count', 'sum', 'mean']
    }).round(4)
    stock_stats.columns = ['total_samples', 'positive_samples', 'positive_rate']
    stock_stats = stock_stats.sort_values('positive_samples', ascending=False)
    
    print(f"Stock statistics:")
    print(stock_stats.head(10))
    
    # ç­›é€‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨
    eligible_stocks = stock_stats[
        (stock_stats['total_samples'] >= args.min_samples) & 
        (stock_stats['positive_samples'] >= args.min_positive)
    ].index.tolist()
    
    print(f"\nâœ… Found {len(eligible_stocks)} eligible stocks (min_samples={args.min_samples}, min_positive={args.min_positive})")
    print(f"Eligible stocks: {eligible_stocks}")
    
    if len(eligible_stocks) == 0:
        print("âŒ No stocks meet the minimum requirements")
        return
    
    # ä¸ºæ¯åªè‚¡ç¥¨è®­ç»ƒæ¨¡å‹
    print(f"\nğŸš€ Training models for {len(eligible_stocks)} stocks...")
    stock_results = []
    
    for stock in eligible_stocks:
        df_stock = df[df['ticker'] == stock].copy()
        result = train_stock_model(df_stock, feature_cols, args, stock)
        if result:
            stock_results.append(result)
    
    if not stock_results:
        print("âŒ No successful stock models trained")
        return
    
    print(f"\nâœ… Successfully trained {len(stock_results)} stock models")
    
    # æ±‡æ€»ç»“æœåˆ†æ
    print(f"\nğŸ“Š Stock-wise Performance Analysis:")
    print("=" * 80)
    
    # åˆ›å»ºç»“æœè¡¨æ ¼
    results_summary = []
    for result in stock_results:
        summary = {
            'Stock': result['stock'],
            'TrainSamples': result['train_samples'],
            'ValidSamples': result['valid_samples'],
            'TrainPos': result['train_positive'],
            'ValidPos': result['valid_positive'],
            'PR-AUC': result['metrics']['PR-AUC'],
            'ROC-AUC': result['metrics']['ROC-AUC'],
            'P@0.1%': result['metrics'].get('Precision@0.1%', 0),
            'P@1%': result['metrics'].get('Precision@1.0%', 0),
            'TrainingTime': result['training_time']
        }
        results_summary.append(summary)
    
    results_df = pd.DataFrame(results_summary)
    results_df = results_df.sort_values('PR-AUC', ascending=False)
    
    print(results_df.round(4).to_string(index=False))
    
    # ç»Ÿè®¡åˆ†æ
    print(f"\nğŸ“ˆ Performance Statistics:")
    print(f"Average PR-AUC: {results_df['PR-AUC'].mean():.4f} Â± {results_df['PR-AUC'].std():.4f}")
    print(f"Best PR-AUC: {results_df['PR-AUC'].max():.4f} ({results_df.loc[results_df['PR-AUC'].idxmax(), 'Stock']})")
    print(f"Worst PR-AUC: {results_df['PR-AUC'].min():.4f} ({results_df.loc[results_df['PR-AUC'].idxmin(), 'Stock']})")
    print(f"Total training time: {results_df['TrainingTime'].sum():.1f}s")
    
    # è·¨è‚¡ç¥¨æ³›åŒ–æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
    print(f"\nğŸ”„ Cross-stock Generalization Test...")
    cross_stock_results = []
    
    for i, train_result in enumerate(stock_results[:3]):  # åªæµ‹è¯•å‰3ä¸ªè¡¨ç°æœ€å¥½çš„è‚¡ç¥¨
        train_stock = train_result['stock']
        train_model = train_result['model']
        
        for j, test_result in enumerate(stock_results):
            test_stock = test_result['stock']
            if train_stock == test_stock:
                continue
            
            # ä½¿ç”¨è®­ç»ƒè‚¡ç¥¨çš„æ¨¡å‹é¢„æµ‹æµ‹è¯•è‚¡ç¥¨
            try:
                if args.use_focal_loss and not args.use_ensemble:
                    y_pred_cross = train_model.predict(test_result['y_true'].values.reshape(-1, len(train_result['features'])))
                    y_pred_cross = 1 / (1 + np.exp(-y_pred_cross))
                else:
                    # éœ€è¦æ„é€ æµ‹è¯•æ•°æ®
                    df_test_stock = df[df['ticker'] == test_stock].copy()
                    test_mask = df_test_stock["è‡ªç„¶æ—¥"].astype(str).str.contains(args.valid_regex)
                    df_test = df_test_stock[test_mask].copy()
                    
                    if len(df_test) == 0:
                        continue
                    
                    df_test = enhance_features(df_test)
                    available_features = [col for col in train_result['features'] if col in df_test.columns]
                    X_test = df_test[available_features].fillna(0)
                    
                    if len(available_features) < len(train_result['features']) * 0.8:  # å¦‚æœç‰¹å¾ç¼ºå¤±å¤ªå¤šï¼Œè·³è¿‡
                        continue
                    
                    y_pred_cross = train_model.predict_proba(X_test)[:, 1]
                
                cross_metrics = comprehensive_evaluation(test_result['y_true'], y_pred_cross)
                cross_stock_results.append({
                    'TrainStock': train_stock,
                    'TestStock': test_stock,
                    'CrossPR-AUC': cross_metrics['PR-AUC'],
                    'OriginalPR-AUC': test_result['metrics']['PR-AUC'],
                    'Performance_Ratio': cross_metrics['PR-AUC'] / test_result['metrics']['PR-AUC']
                })
                
            except Exception as e:
                print(f"âš ï¸ Cross-stock test failed ({train_stock}->{test_stock}): {e}")
                continue
    
    if cross_stock_results:
        cross_df = pd.DataFrame(cross_stock_results)
        print("\nCross-stock Performance (Top examples):")
        print(cross_df.head(10).round(4).to_string(index=False))
        print(f"\nAverage cross-stock performance ratio: {cross_df['Performance_Ratio'].mean():.3f}")
    
    # ä¿å­˜ç»“æœ
    if args.eval_output_dir is not None:
        eval_output_dir = args.eval_output_dir
    else:
        eval_output_dir = os.path.join("results", "stock_wise_results")
    
    os.makedirs(eval_output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    detailed_results = {
        'summary': results_summary,
        'cross_stock': cross_stock_results,
        'args': vars(args),
        'timestamp': timestamp,
        'total_time': time.time() - t0
    }
    
    results_file = os.path.join(eval_output_dir, f"stock_wise_results_{timestamp}.json")
    with open(results_file, 'w') as f:
        json.dump(detailed_results, f, indent=2, default=str)
    
    # ä¿å­˜CSVè¡¨æ ¼
    csv_file = os.path.join(eval_output_dir, f"stock_performance_{timestamp}.csv")
    results_df.to_csv(csv_file, index=False)
    
    if cross_stock_results:
        cross_csv_file = os.path.join(eval_output_dir, f"cross_stock_performance_{timestamp}.csv")
        cross_df.to_csv(cross_csv_file, index=False)
    
    print(f"\nğŸ“ Results saved to: {eval_output_dir}")
    print(f"ğŸ“Š Performance table: {csv_file}")
    print(f"ğŸ“‹ Detailed results: {results_file}")
    
    print(f"\nTotal execution time: {time.time()-t0:.1f}s")

if __name__ == "__main__":
    main()