#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ¨¡å‹ä¿å­˜è¾…åŠ©è„šæœ¬
==============

å°†è®­ç»ƒå¥½çš„LightGBMæ¨¡å‹å’Œç‰¹å¾åˆ—è¡¨ä¿å­˜ä¸ºé€‚åˆmanipulation_detection_heatmap.pyä½¿ç”¨çš„æ ¼å¼ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
1. è®­ç»ƒå®Œæˆåï¼Œè°ƒç”¨save_model_for_analysiså‡½æ•°
2. æˆ–è€…è¿è¡Œæ­¤è„šæœ¬ç‹¬ç«‹ä¿å­˜ç°æœ‰æ¨¡å‹

ç¤ºä¾‹ï¼š
python scripts/analysis/save_model_for_analysis.py \
  --model_path "path/to/trained_model.pkl" \
  --features_list "feature1,feature2,feature3" \
  --output_dir "results/saved_models"
"""

import argparse
import json
import os
import pickle
import joblib
from pathlib import Path
from typing import List, Union

import lightgbm as lgb
import pandas as pd


def save_model_for_analysis(
    model, 
    feature_names: List[str], 
    output_dir: str, 
    model_name: str = "spoofing_model"
):
    """
    ä¿å­˜æ¨¡å‹å’Œç‰¹å¾åˆ—è¡¨ï¼Œä¾›åˆ†æè„šæœ¬ä½¿ç”¨
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        feature_names: ç‰¹å¾åç§°åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        model_name: æ¨¡å‹åç§°å‰ç¼€
    """
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ’¾ ä¿å­˜æ¨¡å‹å’Œç‰¹å¾åˆ°: {output_path}")
    
    # ä¿å­˜ç‰¹å¾åˆ—è¡¨
    features_path = output_path / f"{model_name}_features.json"
    with open(features_path, 'w') as f:
        json.dump(feature_names, f, indent=2)
    print(f"âœ… ç‰¹å¾åˆ—è¡¨å·²ä¿å­˜: {features_path}")
    
    # ä¿å­˜æ¨¡å‹
    if hasattr(model, 'booster_'):
        # LightGBM sklearnæ¥å£
        model_path = output_path / f"{model_name}.pkl"
        with open(model_path, 'wb') as f:
            pickle.dump({
                'model': model,
                'features': feature_names,
                'model_type': 'lightgbm_sklearn'
            }, f)
        print(f"âœ… LightGBMæ¨¡å‹å·²ä¿å­˜: {model_path}")
        
        # å¦å¤–ä¿å­˜ä¸ºLightGBMåŸç”Ÿæ ¼å¼
        lgb_path = output_path / f"{model_name}.txt"
        model.booster_.save_model(str(lgb_path))
        print(f"âœ… LightGBMåŸç”Ÿæ ¼å¼å·²ä¿å­˜: {lgb_path}")
        
    elif hasattr(model, 'save_model'):
        # LightGBMåŸç”Ÿæ¥å£
        lgb_path = output_path / f"{model_name}.txt"
        model.save_model(str(lgb_path))
        
        # ä¿å­˜æ¨¡å‹å’Œç‰¹å¾çš„ç»„åˆ
        model_path = output_path / f"{model_name}.pkl"
        with open(model_path, 'wb') as f:
            pickle.dump({
                'model': model,
                'features': feature_names,
                'model_type': 'lightgbm_native'
            }, f)
        print(f"âœ… LightGBMæ¨¡å‹å·²ä¿å­˜: {model_path}")
        
    else:
        # å…¶ä»–æ¨¡å‹ï¼ˆsklearnç­‰ï¼‰
        model_path = output_path / f"{model_name}.pkl"
        with open(model_path, 'wb') as f:
            pickle.dump({
                'model': model,
                'features': feature_names,
                'model_type': 'sklearn'
            }, f)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")
    
    # ä¿å­˜ä½¿ç”¨è¯´æ˜
    readme_path = output_path / "README.md"
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(f"""# ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶

## æ–‡ä»¶è¯´æ˜
- `{model_name}.pkl`: å®Œæ•´æ¨¡å‹å’Œç‰¹å¾ä¿¡æ¯ï¼ˆæ¨èç”¨äºåˆ†æè„šæœ¬ï¼‰
- `{model_name}_features.json`: ç‰¹å¾åç§°åˆ—è¡¨
- `{model_name}.txt`: LightGBMåŸç”Ÿæ ¼å¼ï¼ˆå¦‚æœé€‚ç”¨ï¼‰

## ä½¿ç”¨æ–¹æ³•

### åœ¨manipulation_detection_heatmap.pyä¸­ä½¿ç”¨ï¼š

```bash
python scripts/analysis/manipulation_detection_heatmap.py \\
  --data_root "/path/to/data" \\
  --model_path "{output_path}/{model_name}.pkl" \\
  --output_dir "results/manipulation_analysis"
```

æˆ–è€…ä½¿ç”¨åŸç”Ÿæ ¼å¼ï¼š

```bash
python scripts/analysis/manipulation_detection_heatmap.py \\
  --data_root "/path/to/data" \\
  --model_path "{output_path}/{model_name}.txt" \\
  --model_features_path "{output_path}/{model_name}_features.json" \\
  --output_dir "results/manipulation_analysis"
```

## æ¨¡å‹ä¿¡æ¯
- ç‰¹å¾æ•°é‡: {len(feature_names)}
- ä¿å­˜æ—¶é—´: {pd.Timestamp.now()}
""")
    
    print(f"âœ… è¯´æ˜æ–‡æ¡£å·²ä¿å­˜: {readme_path}")
    print(f"ğŸ¯ æ¨¡å‹ä¿å­˜å®Œæˆï¼å¯ä»¥åœ¨manipulation_detection_heatmap.pyä¸­ä½¿ç”¨ --model_path {model_path}")


def load_and_resave_model(model_path: str, output_dir: str, feature_names: List[str] = None):
    """
    åŠ è½½ç°æœ‰æ¨¡å‹å¹¶é‡æ–°ä¿å­˜ä¸ºåˆ†æè„šæœ¬å…¼å®¹æ ¼å¼
    
    Args:
        model_path: ç°æœ‰æ¨¡å‹è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        feature_names: ç‰¹å¾åç§°åˆ—è¡¨ï¼ˆå¦‚æœæ¨¡å‹ä¸­æ²¡æœ‰ä¿å­˜ï¼‰
    """
    print(f"ğŸ“¦ åŠ è½½ç°æœ‰æ¨¡å‹: {model_path}")
    
    try:
        # å°è¯•ä¸åŒçš„åŠ è½½æ–¹æ³•
        if model_path.endswith('.pkl'):
            with open(model_path, 'rb') as f:
                model_data = pickle.load(f)
            
            if isinstance(model_data, dict):
                model = model_data.get('model')
                features = model_data.get('features', feature_names)
            else:
                model = model_data
                features = feature_names
                
        elif model_path.endswith('.joblib'):
            model_data = joblib.load(model_path)
            if isinstance(model_data, dict):
                model = model_data.get('model')
                features = model_data.get('features', feature_names)
            else:
                model = model_data
                features = feature_names
                
        elif model_path.endswith('.txt'):
            # LightGBMåŸç”Ÿæ ¼å¼
            model = lgb.Booster(model_file=model_path)
            features = feature_names
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹æ ¼å¼: {model_path}")
        
        if features is None:
            raise ValueError("æ— æ³•è·å–ç‰¹å¾åˆ—è¡¨ï¼Œè¯·æä¾›feature_nameså‚æ•°")
        
        # é‡æ–°ä¿å­˜
        model_name = Path(model_path).stem
        save_model_for_analysis(model, features, output_dir, model_name)
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ä¿å­˜æ¨¡å‹ä¾›åˆ†æè„šæœ¬ä½¿ç”¨")
    parser.add_argument("--model_path", required=True, help="ç°æœ‰æ¨¡å‹è·¯å¾„")
    parser.add_argument("--output_dir", required=True, help="è¾“å‡ºç›®å½•")
    parser.add_argument("--features_list", help="ç‰¹å¾åç§°ï¼ˆé€—å·åˆ†éš”ï¼‰")
    parser.add_argument("--features_file", help="ç‰¹å¾åç§°æ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    # è·å–ç‰¹å¾åˆ—è¡¨
    feature_names = None
    if args.features_list:
        feature_names = [f.strip() for f in args.features_list.split(',')]
    elif args.features_file and os.path.exists(args.features_file):
        if args.features_file.endswith('.json'):
            with open(args.features_file, 'r') as f:
                feature_names = json.load(f)
        else:
            with open(args.features_file, 'r') as f:
                feature_names = [line.strip() for line in f if line.strip()]
    
    if feature_names:
        print(f"ğŸ“‹ åŠ è½½äº† {len(feature_names)} ä¸ªç‰¹å¾")
    else:
        print("âš ï¸ æœªæä¾›ç‰¹å¾åˆ—è¡¨ï¼Œå°†å°è¯•ä»æ¨¡å‹ä¸­æå–")
    
    # é‡æ–°ä¿å­˜æ¨¡å‹
    load_and_resave_model(args.model_path, args.output_dir, feature_names)


# å¯ä»¥ç›´æ¥åœ¨è®­ç»ƒè„šæœ¬ä¸­è°ƒç”¨çš„å‡½æ•°
def save_training_results(
    model, 
    feature_names: List[str], 
    results: dict, 
    output_base_dir: str = "results"
):
    """
    è®­ç»ƒå®Œæˆåä¿å­˜æ‰€æœ‰ç»“æœ
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        feature_names: ç‰¹å¾åç§°åˆ—è¡¨
        results: è®­ç»ƒç»“æœå­—å…¸
        output_base_dir: è¾“å‡ºåŸºç¡€ç›®å½•
    """
    import datetime
    
    # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = Path(output_base_dir) / f"spoofing_model_{timestamp}"
    
    # ä¿å­˜æ¨¡å‹
    save_model_for_analysis(model, feature_names, str(output_dir))
    
    # ä¿å­˜è®­ç»ƒç»“æœ
    results_path = output_dir / "training_results.json"
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2)
    print(f"âœ… è®­ç»ƒç»“æœå·²ä¿å­˜: {results_path}")
    
    return str(output_dir)


if __name__ == "__main__":
    main()

"""
ä½¿ç”¨ç¤ºä¾‹ï¼š

1. é‡æ–°ä¿å­˜ç°æœ‰æ¨¡å‹ï¼š
python scripts/analysis/save_model_for_analysis.py \
  --model_path "results/lgb_model.pkl" \
  --output_dir "results/saved_for_analysis" \
  --features_list "feature1,feature2,feature3"

2. åœ¨è®­ç»ƒè„šæœ¬ä¸­ä½¿ç”¨ï¼š
from scripts.analysis.save_model_for_analysis import save_training_results

# è®­ç»ƒå®Œæˆå
output_dir = save_training_results(
    model=trained_model,
    feature_names=feature_columns,
    results=evaluation_metrics
)
print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {output_dir}")
""" 