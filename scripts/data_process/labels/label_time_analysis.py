#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ ‡ç­¾æ—¶é—´åˆ†å¸ƒåˆ†æ
åˆ†ææ­£æ ·æœ¬åœ¨ä¸åŒæ—¶é—´æ®µçš„åˆ†å¸ƒæƒ…å†µ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import argparse
from datetime import time
from rich.console import Console
from rich.table import Table
from rich import print as rprint
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

console = Console()

def classify_time_period(time_obj):
    """åˆ†ç±»æ—¶é—´æ®µ"""
    if pd.isna(time_obj):
        return "æœªçŸ¥æ—¶é—´"
    
    if isinstance(time_obj, str):
        time_obj = pd.to_datetime(time_obj).time()
    elif hasattr(time_obj, 'time'):
        time_obj = time_obj.time()
    
    if time(9, 15) <= time_obj < time(9, 25):
        return "é›†åˆç«ä»·æ—©æœŸ"
    elif time(9, 25) <= time_obj < time(9, 30):
        return "é›†åˆç«ä»·æ™šæœŸ"
    elif time(9, 30) <= time_obj <= time(10, 0):
        return "æ—©ç›˜å¼€ç›˜(9:30-10:00)"
    elif time(10, 0) < time_obj < time(11, 30):
        return "ä¸Šåˆæ­£å¸¸äº¤æ˜“"
    elif time(11, 30) <= time_obj < time(13, 0):
        return "åˆä¼‘æ—¶é—´"
    elif time(13, 0) <= time_obj <= time(13, 15):
        return "åˆç›˜å¼€ç›˜(13:00-13:15)"
    elif time(13, 15) < time_obj < time(14, 45):
        return "ä¸‹åˆæ­£å¸¸äº¤æ˜“"
    elif time(14, 45) <= time_obj <= time(15, 0):
        return "å°¾ç›˜æ”¶ç›˜"
    else:
        return "ç›˜å¤–æ—¶é—´"

def get_time_stats(time_obj):
    """è·å–æ—¶é—´ç»Ÿè®¡ä¿¡æ¯"""
    if pd.isna(time_obj):
        return {"hour": None, "minute": None, "period": "æœªçŸ¥æ—¶é—´"}
    
    if isinstance(time_obj, str):
        dt = pd.to_datetime(time_obj)
    else:
        dt = time_obj
    
    return {
        "hour": dt.hour,
        "minute": dt.minute,
        "period": classify_time_period(dt)
    }

def analyze_label_time_distribution(labels_dir: Path, output_dir: Path = None):
    """åˆ†ææ ‡ç­¾æ—¶é—´åˆ†å¸ƒ"""
    
    console.print(f"\n[bold green]ğŸ“Š æ ‡ç­¾æ—¶é—´åˆ†å¸ƒåˆ†æ[/bold green]")
    console.print(f"[dim]æ ‡ç­¾ç›®å½•: {labels_dir}[/dim]")
    
    # æŸ¥æ‰¾æ‰€æœ‰æ ‡ç­¾æ–‡ä»¶
    label_files = list(labels_dir.glob("labels_*.parquet"))
    if not label_files:
        console.print(f"[red]âŒ æœªæ‰¾åˆ°æ ‡ç­¾æ–‡ä»¶: {labels_dir}[/red]")
        return
    
    console.print(f"[dim]å‘ç° {len(label_files)} ä¸ªæ ‡ç­¾æ–‡ä»¶[/dim]")
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®
    all_data = []
    for file_path in sorted(label_files):
        try:
            df = pd.read_parquet(file_path)
            all_data.append(df)
        except Exception as e:
            console.print(f"[yellow]è­¦å‘Š: è¯»å–æ–‡ä»¶å¤±è´¥ {file_path.name}: {e}[/yellow]")
    
    if not all_data:
        console.print("[red]âŒ æ— æœ‰æ•ˆæ•°æ®æ–‡ä»¶[/red]")
        return
    
    # åˆå¹¶æ•°æ®
    df_all = pd.concat(all_data, ignore_index=True)
    console.print(f"[green]âœ… åŠ è½½æ•°æ®: {len(df_all):,} æ¡è®°å½•[/green]")
    
    # æ•°æ®é¢„å¤„ç†
    if 'å§”æ‰˜_datetime' in df_all.columns:
        df_all['å§”æ‰˜_datetime'] = pd.to_datetime(df_all['å§”æ‰˜_datetime'])
        df_all['å§”æ‰˜_time'] = df_all['å§”æ‰˜_datetime'].dt.time
        df_all['å§”æ‰˜_hour'] = df_all['å§”æ‰˜_datetime'].dt.hour
        df_all['å§”æ‰˜_minute'] = df_all['å§”æ‰˜_datetime'].dt.minute
        df_all['æ—¶é—´æ®µ'] = df_all['å§”æ‰˜_time'].apply(classify_time_period)
    else:
        console.print("[red]âŒ ç¼ºå°‘æ—¶é—´åˆ—[/red]")
        return
    
    # è¯†åˆ«æ ‡ç­¾åˆ—
    label_cols = [col for col in df_all.columns if 
                  any(keyword in col.lower() for keyword in ['label', 'flag', 'spoofing']) 
                  and col not in ['è‡ªç„¶æ—¥', 'ticker']]
    
    if not label_cols:
        console.print("[red]âŒ æœªæ‰¾åˆ°æ ‡ç­¾åˆ—[/red]")
        return
    
    console.print(f"[dim]æ ‡ç­¾åˆ—: {label_cols}[/dim]\n")
    
    # 1. æ€»ä½“ç»Ÿè®¡
    console.print("[bold cyan]ğŸ“ˆ æ€»ä½“ç»Ÿè®¡[/bold cyan]")
    table = Table(show_header=True, header_style="bold magenta")
    table.add_column("æŒ‡æ ‡")
    table.add_column("æ•°å€¼", justify="right")
    
    table.add_row("æ€»æ ·æœ¬æ•°", f"{len(df_all):,}")
    table.add_row("æ—¶é—´èŒƒå›´", f"{df_all['å§”æ‰˜_datetime'].min()} ~ {df_all['å§”æ‰˜_datetime'].max()}")
    
    for col in label_cols:
        if col in df_all.columns:
            positive_count = df_all[col].sum() if df_all[col].dtype in ['int64', 'float64'] else 0
            positive_rate = positive_count / len(df_all) * 100
            table.add_row(f"{col} æ­£æ ·æœ¬", f"{positive_count:,} ({positive_rate:.3f}%)")
    
    console.print(table)
    console.print()
    
    # 2. æ—¶é—´æ®µåˆ†å¸ƒåˆ†æ
    console.print("[bold cyan]â° æ—¶é—´æ®µåˆ†å¸ƒåˆ†æ[/bold cyan]")
    
    time_stats = df_all.groupby('æ—¶é—´æ®µ').agg({
        'å§”æ‰˜_datetime': 'count',
        **{col: ['sum', 'mean'] for col in label_cols if col in df_all.columns}
    }).round(4)
    
    # é‡å‘½ååˆ—
    time_stats.columns = ['_'.join(col).strip('_') for col in time_stats.columns]
    time_stats = time_stats.rename(columns={'å§”æ‰˜_datetime_count': 'æ ·æœ¬æ•°'})
    
    console.print(time_stats)
    console.print()
    
    # 3. å°æ—¶çº§åˆ†å¸ƒ
    console.print("[bold cyan]ğŸ• å°æ—¶çº§åˆ†å¸ƒ[/bold cyan]")
    hour_stats = df_all.groupby('å§”æ‰˜_hour').agg({
        'å§”æ‰˜_datetime': 'count',
        **{col: ['sum', 'mean'] for col in label_cols if col in df_all.columns}
    }).round(4)
    
    hour_stats.columns = ['_'.join(col).strip('_') for col in hour_stats.columns]
    hour_stats = hour_stats.rename(columns={'å§”æ‰˜_datetime_count': 'æ ·æœ¬æ•°'})
    
    console.print(hour_stats)
    console.print()
    
    # 4. å¯è§†åŒ–åˆ†æ
    if output_dir:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        console.print(f"[bold cyan]ğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ -> {output_dir}[/bold cyan]")
        
        # è®¾ç½®å›¾å½¢æ ·å¼
        plt.style.use('default')
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('æ ‡ç­¾æ—¶é—´åˆ†å¸ƒåˆ†æ', fontsize=16, fontweight='bold')
        
        # å­å›¾1: æ—¶é—´æ®µæ ·æœ¬æ•°åˆ†å¸ƒ
        time_counts = df_all['æ—¶é—´æ®µ'].value_counts()
        axes[0, 0].bar(range(len(time_counts)), time_counts.values)
        axes[0, 0].set_xticks(range(len(time_counts)))
        axes[0, 0].set_xticklabels(time_counts.index, rotation=45, ha='right')
        axes[0, 0].set_title('å„æ—¶é—´æ®µæ ·æœ¬æ•°åˆ†å¸ƒ')
        axes[0, 0].set_ylabel('æ ·æœ¬æ•°')
        
        # å­å›¾2: ä¸»è¦æ ‡ç­¾çš„æ—¶é—´æ®µåˆ†å¸ƒ
        main_label = 'y_label' if 'y_label' in label_cols else label_cols[0]
        if main_label in df_all.columns:
            positive_by_period = df_all[df_all[main_label] == 1]['æ—¶é—´æ®µ'].value_counts()
            axes[0, 1].bar(range(len(positive_by_period)), positive_by_period.values, color='red', alpha=0.7)
            axes[0, 1].set_xticks(range(len(positive_by_period)))
            axes[0, 1].set_xticklabels(positive_by_period.index, rotation=45, ha='right')
            axes[0, 1].set_title(f'{main_label} æ­£æ ·æœ¬æ—¶é—´æ®µåˆ†å¸ƒ')
            axes[0, 1].set_ylabel('æ­£æ ·æœ¬æ•°')
        
        # å­å›¾3: å°æ—¶çº§åˆ†å¸ƒ
        hour_counts = df_all['å§”æ‰˜_hour'].value_counts().sort_index()
        axes[1, 0].plot(hour_counts.index, hour_counts.values, marker='o')
        axes[1, 0].set_title('å°æ—¶çº§æ ·æœ¬åˆ†å¸ƒ')
        axes[1, 0].set_xlabel('å°æ—¶')
        axes[1, 0].set_ylabel('æ ·æœ¬æ•°')
        axes[1, 0].grid(True, alpha=0.3)
        
        # å­å›¾4: æ­£æ ·æœ¬ç‡æ—¶é—´åˆ†å¸ƒ
        if main_label in df_all.columns:
            hour_positive_rate = df_all.groupby('å§”æ‰˜_hour')[main_label].mean() * 100
            axes[1, 1].bar(hour_positive_rate.index, hour_positive_rate.values, alpha=0.7, color='orange')
            axes[1, 1].set_title(f'{main_label} å„å°æ—¶æ­£æ ·æœ¬ç‡')
            axes[1, 1].set_xlabel('å°æ—¶')
            axes[1, 1].set_ylabel('æ­£æ ·æœ¬ç‡ (%)')
            axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plot_file = output_dir / "label_time_distribution.png"
        plt.savefig(plot_file, dpi=300, bbox_inches='tight')
        plt.close()
        
        console.print(f"[green]âœ… å›¾è¡¨å·²ä¿å­˜: {plot_file}[/green]")
        
        # ä¿å­˜è¯¦ç»†ç»Ÿè®¡æ•°æ®
        stats_file = output_dir / "time_distribution_stats.xlsx"
        with pd.ExcelWriter(stats_file) as writer:
            time_stats.to_excel(writer, sheet_name='æ—¶é—´æ®µç»Ÿè®¡')
            hour_stats.to_excel(writer, sheet_name='å°æ—¶ç»Ÿè®¡')
            
            # æ·»åŠ åŸå§‹æ•°æ®æ ·æœ¬
            sample_data = df_all[['è‡ªç„¶æ—¥', 'ticker', 'å§”æ‰˜_datetime', 'æ—¶é—´æ®µ', 'å§”æ‰˜æ•°é‡'] + label_cols].head(1000)
            sample_data.to_excel(writer, sheet_name='æ•°æ®æ ·æœ¬', index=False)
        
        console.print(f"[green]âœ… ç»Ÿè®¡æ•°æ®å·²ä¿å­˜: {stats_file}[/green]")
    
    # 5. å…³é”®å‘ç°æ€»ç»“
    console.print("[bold yellow]ğŸ” å…³é”®å‘ç°[/bold yellow]")
    
    main_label = 'y_label' if 'y_label' in label_cols else label_cols[0]
    if main_label in df_all.columns:
        # æ£€æŸ¥å¼€ç›˜æ—¶é—´æ®µæ­£æ ·æœ¬æ¯”ä¾‹
        opening_periods = ['æ—©ç›˜å¼€ç›˜(9:30-10:00)', 'åˆç›˜å¼€ç›˜(13:00-13:15)']
        opening_data = df_all[df_all['æ—¶é—´æ®µ'].isin(opening_periods)]
        
        if len(opening_data) > 0:
            opening_positive = opening_data[main_label].sum()
            opening_total = len(opening_data)
            opening_rate = opening_positive / opening_total * 100
            
            console.print(f"â€¢ å¼€ç›˜æ—¶é—´æ®µæ ·æœ¬: {opening_total:,} æ¡")
            console.print(f"â€¢ å¼€ç›˜æ—¶é—´æ®µæ­£æ ·æœ¬: {opening_positive} æ¡ ({opening_rate:.3f}%)")
            
            if opening_rate < 1.0:
                console.print("[green]âœ… å¼€ç›˜æ—¶é—´æ®µæ­£æ ·æœ¬æ¯”ä¾‹è¾ƒä½ï¼Œä¿®å¤æœ‰æ•ˆ[/green]")
            else:
                console.print("[yellow]âš ï¸ å¼€ç›˜æ—¶é—´æ®µæ­£æ ·æœ¬æ¯”ä¾‹ä»ç„¶è¾ƒé«˜[/yellow]")
        
        # æ£€æŸ¥å¼‚å¸¸æ—¶é—´æ®µ
        abnormal_periods = ['é›†åˆç«ä»·æ™šæœŸ', 'åˆä¼‘æ—¶é—´', 'ç›˜å¤–æ—¶é—´']
        abnormal_data = df_all[df_all['æ—¶é—´æ®µ'].isin(abnormal_periods)]
        
        if len(abnormal_data) > 0:
            abnormal_positive = abnormal_data[main_label].sum()
            abnormal_total = len(abnormal_data)
            abnormal_rate = abnormal_positive / abnormal_total * 100
            
            console.print(f"â€¢ å¼‚å¸¸æ—¶é—´æ®µæ ·æœ¬: {abnormal_total:,} æ¡")
            console.print(f"â€¢ å¼‚å¸¸æ—¶é—´æ®µæ­£æ ·æœ¬: {abnormal_positive} æ¡ ({abnormal_rate:.3f}%)")
    
    return df_all

def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description="æ ‡ç­¾æ—¶é—´åˆ†å¸ƒåˆ†æ")
    parser.add_argument("--labels_dir", required=True, help="æ ‡ç­¾æ–‡ä»¶ç›®å½•")
    parser.add_argument("--output_dir", help="è¾“å‡ºç›®å½•(å¯é€‰)")
    
    args = parser.parse_args()
    
    labels_dir = Path(args.labels_dir)
    if not labels_dir.exists():
        console.print(f"[red]âŒ æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {labels_dir}[/red]")
        return
    
    output_dir = Path(args.output_dir) if args.output_dir else None
    
    # æ‰§è¡Œåˆ†æ
    analyze_label_time_distribution(labels_dir, output_dir)

if __name__ == "__main__":
    main() 


"""
python scripts/data_process/labels/label_time_analysis.py \
    --labels_dir "/home/ma-user/code/fenglang/Spoofing Detect/data/labels_enhanced" \
    --output_dir "/home/ma-user/code/fenglang/Spoofing Detect/data/labels_time_analysis"
"""