#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
label_generator.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ ‡ç­¾ç”Ÿæˆæ¨¡å— - ç¬¬äºŒé˜¶æ®µæ ‡ç­¾è®¡ç®—
â€¢ ä»å§”æ‰˜äº‹ä»¶æµç”Ÿæˆæ¬ºéª—æ ‡ç­¾
â€¢ æ”¯æŒå¤šç§æ ‡ç­¾è§„åˆ™ï¼ˆR1, R2, æ‰©å±•è§„åˆ™ï¼‰
â€¢ æ‰¹é‡å¤„ç†å¤šæ—¥æœŸæ•°æ®
â€¢ æ¨¡å—åŒ–æ ‡ç­¾è®¡ç®—æµæ°´çº¿
"""

import sys
import pandas as pd
import polars as pl
from pathlib import Path
from typing import Set, List, Optional, Union, Dict
import argparse
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
from rich import print as rprint

# å¯¼å…¥æ ‡ç­¾ç”Ÿæˆç»„ä»¶
try:
    # ç›¸å¯¹å¯¼å…¥
    from ..labeling import improved_spoofing_rules_polars
    from ..enhanced_labeling_no_leakage import enhanced_spoofing_rules_no_leakage
    from ..utils import console
except ImportError:
    # ç»å¯¹å¯¼å…¥
    sys.path.append(str(Path(__file__).parent.parent))
    from labeling import improved_spoofing_rules_polars
    from enhanced_labeling_no_leakage import enhanced_spoofing_rules_no_leakage
    from utils import console

console = Console()

class LabelGenerator:
    """æ ‡ç­¾ç”Ÿæˆå™¨"""
    
    def __init__(self, 
                 r1_ms: int = 50, 
                 r2_ms: int = 1000, 
                 r2_mult: float = 4.0,
                 extended_rules: bool = False,
                 backend: str = "polars"):
        """
        åˆå§‹åŒ–æ ‡ç­¾ç”Ÿæˆå™¨
        
        Args:
            r1_ms: R1è§„åˆ™æ—¶é—´é˜ˆå€¼(ms)
            r2_ms: R2è§„åˆ™æ—¶é—´é˜ˆå€¼(ms) 
            r2_mult: R2è§„åˆ™ä»·å·®å€æ•°
            extended_rules: æ˜¯å¦ä½¿ç”¨æ‰©å±•æ ‡ç­¾è§„åˆ™
            backend: è®¡ç®—åç«¯
        """
        self.r1_ms = r1_ms
        self.r2_ms = r2_ms
        self.r2_mult = r2_mult
        self.extended_rules = extended_rules
        self.backend = backend
        self.console = Console()
        
        # å®šä¹‰æ ‡ç­¾ç”Ÿæˆæµæ°´çº¿
        self.label_pipeline = self._build_label_pipeline()
    
    def _build_label_pipeline(self) -> List[dict]:
        """æ„å»ºæ ‡ç­¾ç”Ÿæˆæµæ°´çº¿"""
        if self.extended_rules:
            pipeline = [
                {
                    "name": "æ‰©å±•æ ‡ç­¾è§„åˆ™",
                    "function": "enhanced_spoofing_rules_no_leakage",
                    "description": f"R1({self.r1_ms}ms) + R2({self.r2_ms}ms, {self.r2_mult}x) + æ‰©å±•è§„åˆ™"
                }
            ]
        else:
            pipeline = [
                {
                    "name": "åŸºç¡€æ ‡ç­¾è§„åˆ™", 
                    "function": "improved_spoofing_rules_polars",
                    "description": f"R1({self.r1_ms}ms) + R2({self.r2_ms}ms, {self.r2_mult}x)"
                }
            ]
        
        return pipeline
    
    def generate_labels_for_data(self,
                                data: Union[pd.DataFrame, pl.DataFrame, pl.LazyFrame],
                                tickers: Optional[Set[str]] = None,
                                show_progress: bool = True) -> Union[pd.DataFrame, pl.DataFrame]:
        """
        ä¸ºç»™å®šæ•°æ®ç”Ÿæˆæ ‡ç­¾
        
        Args:
            data: è¾“å…¥çš„å§”æ‰˜äº‹ä»¶æµæ•°æ®
            tickers: è‚¡ç¥¨ä»£ç ç­›é€‰
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            
        Returns:
            å¸¦æ ‡ç­¾çš„DataFrame
        """
        
        if show_progress:
            progress = Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                BarColumn(),
                console=self.console,
                transient=True
            )
            progress.start()
        
        try:
            # æ•°æ®é¢„å¤„ç†
            if show_progress:
                prep_task = progress.add_task("é¢„å¤„ç†æ•°æ®...", total=100)
            
            if self.backend == "polars":
                df_processed = self._preprocess_polars(data, tickers)
            else:
                df_processed = self._preprocess_pandas(data, tickers)
            
            if show_progress:
                progress.update(prep_task, advance=100)
            
            # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
            if self.backend == "polars":
                if isinstance(df_processed, pl.LazyFrame):
                    data_size = df_processed.collect().height
                else:
                    data_size = df_processed.height
            else:
                data_size = len(df_processed)
            
            if data_size == 0:
                self.console.print("[yellow]è­¦å‘Š: é¢„å¤„ç†åæ•°æ®ä¸ºç©º[/yellow]")
                return df_processed
            
            # æ ‡ç­¾ç”Ÿæˆæµæ°´çº¿
            for i, step in enumerate(self.label_pipeline):
                if show_progress:
                    label_task = progress.add_task(f"ç”Ÿæˆ{step['name']}...", total=100)
                
                try:
                    df_processed = self._execute_label_step(df_processed, step)
                    
                    if show_progress:
                        progress.update(label_task, advance=100)
                        
                except Exception as e:
                    self.console.print(f"[red]é”™è¯¯: {step['name']}ç”Ÿæˆå¤±è´¥: {e}[/red]")
                    if show_progress:
                        progress.update(label_task, advance=100)
                    continue
            
            return df_processed
            
        finally:
            if show_progress:
                progress.stop()
    
    def _preprocess_polars(self, data: Union[pl.DataFrame, pl.LazyFrame], tickers: Optional[Set[str]]) -> pl.LazyFrame:
        """Polarsæ•°æ®é¢„å¤„ç†"""
        if isinstance(data, pl.DataFrame):
            df = data.lazy()
        else:
            df = data
        
        # è‚¡ç¥¨ç­›é€‰
        if tickers:
            df = df.filter(pl.col("ticker").is_in(list(tickers)))
        
        # ç¡®ä¿æ—¶é—´åˆ—ç±»å‹æ­£ç¡®
        try:
            df = df.with_columns([
                pl.col("å§”æ‰˜_datetime").cast(pl.Datetime("ns")),
                pl.col("äº‹ä»¶_datetime").cast(pl.Datetime("ns"))
            ])
        except Exception as e:
            self.console.print(f"[yellow]è­¦å‘Š: æ—¶é—´åˆ—å¤„ç†å¤±è´¥: {e}[/yellow]")
        
        return df
    
    def _preprocess_pandas(self, data: pd.DataFrame, tickers: Optional[Set[str]]) -> pd.DataFrame:
        """Pandasæ•°æ®é¢„å¤„ç†"""
        df = data.copy()
        
        # è‚¡ç¥¨ç­›é€‰
        if tickers:
            df = df[df["ticker"].isin(tickers)]
        
        # ç¡®ä¿æ—¶é—´åˆ—ç±»å‹æ­£ç¡®
        try:
            df["å§”æ‰˜_datetime"] = pd.to_datetime(df["å§”æ‰˜_datetime"])
            df["äº‹ä»¶_datetime"] = pd.to_datetime(df["äº‹ä»¶_datetime"])
        except Exception as e:
            self.console.print(f"[yellow]è­¦å‘Š: æ—¶é—´åˆ—å¤„ç†å¤±è´¥: {e}[/yellow]")
        
        return df
    
    def _execute_label_step(self, data: Union[pd.DataFrame, pl.LazyFrame], step: dict) -> Union[pd.DataFrame, pl.LazyFrame]:
        """æ‰§è¡Œå•ä¸ªæ ‡ç­¾ç”Ÿæˆæ­¥éª¤"""
        func_name = step["function"]
        
        try:
            if func_name == "improved_spoofing_rules_polars":
                if self.backend == "polars":
                    return improved_spoofing_rules_polars(
                        data, self.r1_ms, self.r2_ms, self.r2_mult
                    )
                else:
                    # å¦‚æœæ˜¯pandasï¼Œéœ€è¦å…ˆè½¬æ¢
                    if isinstance(data, pd.DataFrame):
                        pl_data = pl.from_pandas(data).lazy()
                    else:
                        pl_data = data
                    result = improved_spoofing_rules_polars(
                        pl_data, self.r1_ms, self.r2_ms, self.r2_mult
                    )
                    return result.collect().to_pandas()
                    
            elif func_name == "enhanced_spoofing_rules_no_leakage":
                if self.backend == "pandas":
                    return enhanced_spoofing_rules_no_leakage(
                        data, self.r1_ms, self.r2_ms, self.r2_mult
                    )
                else:
                    # polars -> pandas -> polars
                    if isinstance(data, pl.LazyFrame):
                        pd_data = data.collect().to_pandas()
                    else:
                        pd_data = data.to_pandas()
                    result = enhanced_spoofing_rules_no_leakage(
                        pd_data, self.r1_ms, self.r2_ms, self.r2_mult
                    )
                    return pl.from_pandas(result)
            
            return data
            
        except Exception as e:
            self.console.print(f"[red]è­¦å‘Š: {step['name']}ç”Ÿæˆå¤±è´¥: {e}[/red]")
            return data
    
    def process_single_file(self,
                           input_path: Path,
                           output_path: Path,
                           tickers: Optional[Set[str]] = None) -> Dict:
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶
        
        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            tickers: è‚¡ç¥¨ä»£ç ç­›é€‰
            
        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        try:
            self.console.print(f"[cyan]ğŸ“ å¤„ç†æ–‡ä»¶: {input_path.name}[/cyan]")
            
            # åŠ è½½æ•°æ®
            if self.backend == "polars":
                df = pl.read_csv(input_path, try_parse_dates=True)
            else:
                df = pd.read_csv(input_path, parse_dates=["å§”æ‰˜_datetime", "äº‹ä»¶_datetime"])
            
            # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
            if self.backend == "polars":
                if df.height == 0:
                    self.console.print(f"[yellow]è·³è¿‡ç©ºæ–‡ä»¶: {input_path.name}[/yellow]")
                    return {"success": False, "reason": "empty_file"}
            else:
                if len(df) == 0:
                    self.console.print(f"[yellow]è·³è¿‡ç©ºæ–‡ä»¶: {input_path.name}[/yellow]")
                    return {"success": False, "reason": "empty_file"}
            
            # ç”Ÿæˆæ ‡ç­¾
            df_labels = self.generate_labels_for_data(df, tickers=tickers)
            
            # æå–æ ‡ç­¾åˆ— (åªä¿ç•™ä¸»é”® + æ ‡ç­¾ç›¸å…³åˆ—)
            key_cols = ["è‡ªç„¶æ—¥", "ticker", "äº¤æ˜“æ‰€å§”æ‰˜å·"]
            
            if self.backend == "polars":
                if isinstance(df_labels, pl.LazyFrame):
                    df_labels = df_labels.collect()
                
                # è·å–æ ‡ç­¾ç›¸å…³åˆ—
                label_cols = [col for col in df_labels.columns 
                             if any(keyword in col.lower() for keyword in 
                                   ['label', 'flag', 'spoofing', 'r1', 'r2']) and col not in key_cols]
                
                # é€‰æ‹©åˆ—
                final_cols = key_cols + label_cols
                df_final = df_labels.select(final_cols)
                
                # ä¿å­˜ç»“æœ
                output_path.parent.mkdir(parents=True, exist_ok=True)
                df_final.write_parquet(output_path)
                
                # ç»Ÿè®¡ä¿¡æ¯
                total_samples = df_final.height
                positive_samples = 0
                if "y_label" in df_final.columns:
                    positive_samples = df_final["y_label"].sum()
                elif any("label" in col for col in df_final.columns):
                    label_col = next(col for col in df_final.columns if "label" in col)
                    positive_samples = df_final[label_col].sum()
                
            else:
                # Pandaså¤„ç†
                label_cols = [col for col in df_labels.columns 
                             if any(keyword in col.lower() for keyword in 
                                   ['label', 'flag', 'spoofing', 'r1', 'r2']) and col not in key_cols]
                
                final_cols = key_cols + label_cols
                df_final = df_labels[final_cols]
                
                # ä¿å­˜ç»“æœ
                output_path.parent.mkdir(parents=True, exist_ok=True)
                df_final.to_parquet(output_path, index=False)
                
                # ç»Ÿè®¡ä¿¡æ¯
                total_samples = len(df_final)
                positive_samples = 0
                if "y_label" in df_final.columns:
                    positive_samples = df_final["y_label"].sum()
                elif any("label" in col for col in df_final.columns):
                    label_col = next(col for col in df_final.columns if "label" in col)
                    positive_samples = df_final[label_col].sum()
            
            self.console.print(f"[green]âœ“ å·²ä¿å­˜: {output_path.name}[/green]")
            self.console.print(f"  ğŸ“Š æ ·æœ¬æ•°: {total_samples:,}, æ­£æ ·æœ¬: {positive_samples}, æ¯”ä¾‹: {positive_samples/total_samples*100:.4f}%")
            
            return {
                "success": True,
                "total_samples": total_samples,
                "positive_samples": positive_samples,
                "positive_rate": positive_samples / total_samples if total_samples > 0 else 0
            }
            
        except Exception as e:
            self.console.print(f"[red]âŒ å¤„ç†å¤±è´¥ {input_path.name}: {e}[/red]")
            return {"success": False, "reason": str(e)}
    
    def get_summary(self) -> dict:
        """è·å–æ ‡ç­¾ç”Ÿæˆå™¨æ‘˜è¦ä¿¡æ¯"""
        return {
            "r1_ms": self.r1_ms,
            "r2_ms": self.r2_ms,
            "r2_mult": self.r2_mult,
            "extended_rules": self.extended_rules,
            "backend": self.backend,
            "pipeline_steps": len(self.label_pipeline),
            "pipeline_details": self.label_pipeline
        }

def process_event_stream_directory(event_stream_dir: Path,
                                  output_dir: Path,
                                  r1_ms: int = 50,
                                  r2_ms: int = 1000,
                                  r2_mult: float = 4.0,
                                  extended_rules: bool = False,
                                  backend: str = "polars",
                                  tickers: Optional[Set[str]] = None,
                                  dates: Optional[List[str]] = None) -> dict:
    """
    æ‰¹é‡å¤„ç†event_streamç›®å½•ä¸‹çš„æ‰€æœ‰æ—¥æœŸæ–‡ä»¶
    
    Args:
        event_stream_dir: event_streamæ ¹ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        r1_ms: R1è§„åˆ™æ—¶é—´é˜ˆå€¼
        r2_ms: R2è§„åˆ™æ—¶é—´é˜ˆå€¼
        r2_mult: R2è§„åˆ™ä»·å·®å€æ•°
        extended_rules: æ˜¯å¦ä½¿ç”¨æ‰©å±•æ ‡ç­¾è§„åˆ™
        backend: è®¡ç®—åç«¯
        tickers: è‚¡ç¥¨ä»£ç ç­›é€‰
        dates: æŒ‡å®šå¤„ç†æ—¥æœŸ
        
    Returns:
        å¤„ç†ç»“æœç»Ÿè®¡
    """
    
    # åˆ›å»ºæ ‡ç­¾ç”Ÿæˆå™¨
    generator = LabelGenerator(
        r1_ms=r1_ms, r2_ms=r2_ms, r2_mult=r2_mult,
        extended_rules=extended_rules, backend=backend
    )
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    summary = generator.get_summary()
    console.print(f"\n[bold green]ğŸ·ï¸ æ ‡ç­¾ç”Ÿæˆæ¨¡å—[/bold green]")
    console.print(f"[dim]è¾“å…¥ç›®å½•: {event_stream_dir}[/dim]")
    console.print(f"[dim]è¾“å‡ºç›®å½•: {output_dir}[/dim]")
    console.print(f"[dim]è®¡ç®—åç«¯: {summary['backend']}[/dim]")
    console.print(f"[dim]R1é˜ˆå€¼: {summary['r1_ms']}ms[/dim]")
    console.print(f"[dim]R2é˜ˆå€¼: {summary['r2_ms']}ms (Ã—{summary['r2_mult']})[/dim]")
    console.print(f"[dim]æ‰©å±•è§„åˆ™: {summary['extended_rules']}[/dim]")
    console.print(f"[dim]è‚¡ç¥¨ç­›é€‰: {list(tickers) if tickers else 'å…¨éƒ¨'}[/dim]")
    
    for step in summary['pipeline_details']:
        console.print(f"[dim]  â€¢ {step['name']}: {step['description']}[/dim]")
    
    # æŸ¥æ‰¾æ‰€æœ‰å§”æ‰˜äº‹ä»¶æµæ–‡ä»¶
    csv_files = list(event_stream_dir.glob("*/å§”æ‰˜äº‹ä»¶æµ.csv"))
    
    if not csv_files:
        console.print(f"[red]é”™è¯¯: æœªæ‰¾åˆ°å§”æ‰˜äº‹ä»¶æµæ–‡ä»¶ {event_stream_dir}[/red]")
        return {"total": 0, "success": 0, "failed": 0}
    
    # æ—¥æœŸç­›é€‰
    if dates:
        target_dates = set(dates)
        csv_files = [f for f in csv_files if f.parent.name in target_dates]
        missing_dates = target_dates - {f.parent.name for f in csv_files}
        if missing_dates:
            console.print(f"[yellow]è­¦å‘Š: æœªæ‰¾åˆ°æ—¥æœŸ {missing_dates}[/yellow]")
    
    if not csv_files:
        console.print(f"[red]é”™è¯¯: ç­›é€‰åæ— å¯å¤„ç†æ–‡ä»¶[/red]")
        return {"total": 0, "success": 0, "failed": 0}
    
    console.print(f"[dim]å‘ç° {len(csv_files)} ä¸ªæ–‡ä»¶å¾…å¤„ç†[/dim]\n")
    
    # æ‰¹é‡å¤„ç†
    results = {
        "total": len(csv_files), "success": 0, "failed": 0,
        "processed_files": [], "total_samples": 0, "total_positives": 0
    }
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeElapsedColumn(),
        console=console
    ) as progress:
        task = progress.add_task("å¤„ç†æ–‡ä»¶", total=len(csv_files))
        
        for csv_file in sorted(csv_files):
            date_str = csv_file.parent.name
            output_file = output_dir / f"labels_{date_str}.parquet"
            
            progress.update(task, description=f"å¤„ç† {date_str}")
            
            result = generator.process_single_file(csv_file, output_file, tickers)
            
            if result["success"]:
                results["success"] += 1
                results["processed_files"].append(date_str)
                results["total_samples"] += result.get("total_samples", 0)
                results["total_positives"] += result.get("positive_samples", 0)
            else:
                results["failed"] += 1
            
            progress.advance(task)
    
    return results

def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description="æ ‡ç­¾ç”Ÿæˆæ¨¡å—")
    parser.add_argument("--input_dir", required=True, help="event_streamæ ¹ç›®å½•")
    parser.add_argument("--output_dir", required=True, help="æ ‡ç­¾è¾“å‡ºç›®å½•")
    parser.add_argument("--r1_ms", type=int, default=50, help="R1è§„åˆ™æ—¶é—´é˜ˆå€¼(ms)")
    parser.add_argument("--r2_ms", type=int, default=1000, help="R2è§„åˆ™æ—¶é—´é˜ˆå€¼(ms)")
    parser.add_argument("--r2_mult", type=float, default=4.0, help="R2è§„åˆ™ä»·å·®å€æ•°")
    parser.add_argument("--extended", action="store_true", help="ä½¿ç”¨æ‰©å±•æ ‡ç­¾è§„åˆ™")
    parser.add_argument("--backend", choices=["pandas", "polars"], default="polars", help="è®¡ç®—åç«¯")
    parser.add_argument("--tickers", nargs="*", help="è‚¡ç¥¨ä»£ç ç­›é€‰")
    parser.add_argument("--dates", nargs="*", help="æŒ‡å®šå¤„ç†æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDD")
    
    args = parser.parse_args()
    
    # éªŒè¯è¾“å…¥ç›®å½•
    input_dir = Path(args.input_dir)
    if not input_dir.exists():
        console.print(f"[red]é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨ {input_dir}[/red]")
        sys.exit(1)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # å¤„ç†å‚æ•°
    tickers_set = set(args.tickers) if args.tickers else None
    
    try:
        # æ‰§è¡Œæ‰¹é‡å¤„ç†
        results = process_event_stream_directory(
            event_stream_dir=input_dir,
            output_dir=output_dir,
            r1_ms=args.r1_ms,
            r2_ms=args.r2_ms,
            r2_mult=args.r2_mult,
            extended_rules=args.extended,
            backend=args.backend,
            tickers=tickers_set,
            dates=args.dates
        )
        
        # æ˜¾ç¤ºç»“æœ
        console.print(f"\n[bold cyan]ğŸ“Š å¤„ç†å®Œæˆ[/bold cyan]")
        console.print(f"æ€»æ–‡ä»¶æ•°: {results['total']}")
        console.print(f"æˆåŠŸ: {results['success']}")
        console.print(f"å¤±è´¥: {results['failed']}")
        
        if results['success'] > 0:
            console.print(f"[green]âœ… æ ‡ç­¾æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_dir}[/green]")
            console.print(f"å¤„ç†æ—¥æœŸ: {sorted(results['processed_files'])}")
            console.print(f"æ€»æ ·æœ¬æ•°: {results['total_samples']:,}")
            console.print(f"æ­£æ ·æœ¬æ•°: {results['total_positives']:,}")
            if results['total_samples'] > 0:
                positive_rate = results['total_positives'] / results['total_samples']
                console.print(f"æ•´ä½“æ­£æ ·æœ¬æ¯”ä¾‹: {positive_rate*100:.4f}%")
        
        if results['failed'] > 0:
            console.print(f"[red]âš ï¸ {results['failed']} ä¸ªæ–‡ä»¶å¤„ç†å¤±è´¥[/red]")
        
    except Exception as e:
        console.print(f"[red]âŒ å¤„ç†å‡ºé”™: {e}[/red]")
        sys.exit(1)

if __name__ == "__main__":
    main()

"""
ä½¿ç”¨ç¤ºä¾‹:

# åŸºç¡€æ ‡ç­¾ç”Ÿæˆ
python scripts/data_process/labels/label_generator.py \
    --input_dir "/path/to/event_stream" \
    --output_dir "/path/to/labels" \
    --r1_ms 50 --r2_ms 1000 --r2_mult 4.0 \
    --backend polars

# æ‰©å±•æ ‡ç­¾è§„åˆ™
python scripts/data_process/labels/label_generator.py \
    --input_dir "/path/to/event_stream" \
    --output_dir "/path/to/labels" \
    --r1_ms 100 --r2_ms 1000 --r2_mult 1.5 \
    --extended \
    --backend pandas

# æŒ‡å®šè‚¡ç¥¨å’Œæ—¥æœŸ
python scripts/data_process/labels/label_generator.py \
    --input_dir "/path/to/event_stream" \
    --output_dir "/path/to/labels" \
    --tickers 000001.SZ 000002.SZ \
    --dates 20230301 20230302
""" 