#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
label_generator.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ ‡ç­¾ç”Ÿæˆæ¨¡å— - ç¬¬äºŒé˜¶æ®µæ ‡ç­¾è®¡ç®—
â€¢ ä»å§”æ‰˜äº‹ä»¶æµç”Ÿæˆæ¬ºéª—æ ‡ç­¾
â€¢ æ”¯æŒå¤šç§æ ‡ç­¾è§„åˆ™ï¼ˆR1, R2, æ‰©å±•è§„åˆ™ï¼‰
â€¢ æ‰¹é‡å¤„ç†å¤šæ—¥æœŸæ•°æ®
â€¢ æ¨¡å—åŒ–æ ‡ç­¾è®¡ç®—æµæ°´çº¿

é‡è¦ä¿®å¤è¯´æ˜:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
v2.1 - ä¿®å¤å¼€ç›˜æ—¶é—´è¯¯æ ‡é—®é¢˜:
â€¢ æ‰©å±•è§„åˆ™ç°åœ¨æ’é™¤å¼€ç›˜æ—¶é—´æ®µ(09:30-10:00, 13:00-13:15)çš„æ­£å¸¸å¤§å•
â€¢ å¼‚å¸¸æ—¶é—´æ£€æµ‹æ”¹ä¸ºé›†åˆç«ä»·æ™šæœŸ(09:25-09:30)å’Œåˆä¼‘æ—¶é—´
â€¢ æ¿€è¿›å®šä»·åœ¨å¼€ç›˜æ—¶é—´éœ€è¦æ›´æç«¯çš„ä»·æ ¼åç¦»æ‰è§¦å‘
â€¢ ç»¼åˆæ ‡ç­¾ç­–ç•¥æ›´ä¿å®ˆï¼Œé¿å…å°†æ­£å¸¸å¼€ç›˜æ´»åŠ¨è¯¯æ ‡ä¸ºæ¬ºè¯ˆ
"""

import sys
import pandas as pd
import polars as pl
import numpy as np
from pathlib import Path
from typing import Set, List, Optional, Union, Dict
import argparse
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
from rich import print as rprint

console = Console()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åˆ—å®šä¹‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ä¸»é”®åˆ—ï¼ˆç”¨äºæ•°æ®åˆå¹¶å’Œæ ‡è¯†ï¼‰
KEY_COLUMNS = [
    "è‡ªç„¶æ—¥", 
    "ticker", 
    "äº¤æ˜“æ‰€å§”æ‰˜å·"
]

# æ—¶é—´åˆ—ï¼ˆä¸ç”¨äºè®­ç»ƒï¼Œä½†å¯èƒ½ç”¨äºåˆ†æï¼‰
TIME_COLUMNS = [
    "å§”æ‰˜_datetime", 
    "äº‹ä»¶_datetime"
]

# å…ƒæ•°æ®åˆ—ï¼ˆä¿å­˜ä½†ä¸ç”¨äºè®­ç»ƒï¼‰
METADATA_COLUMNS = [
    "å§”æ‰˜æ•°é‡", 
    "æ–¹å‘_å§”æ‰˜", 
    "å§”æ‰˜ä»·æ ¼",
    "äº‹ä»¶ç±»å‹",
    "å­˜æ´»æ—¶é—´_ms"
]

# åŸºç¡€æ ‡ç­¾åˆ—ï¼ˆç”±åŸºç¡€è§„åˆ™ç”Ÿæˆï¼‰
BASE_LABEL_COLUMNS = [
    "flag_R1",           # R1è§„åˆ™ï¼šå¿«é€Ÿæ’¤å•
    "flag_R2",           # R2è§„åˆ™ï¼šä»·æ ¼æ“çºµ  
    "y_label"            # åŸºç¡€ç»¼åˆæ ‡ç­¾ (R1 & R2)
]

# æ‰©å±•æ ‡ç­¾åˆ—ï¼ˆç”±æ‰©å±•è§„åˆ™ç”Ÿæˆï¼‰
ENHANCED_LABEL_COLUMNS = [
    "extreme_price_deviation",      # æç«¯ä»·æ ¼åç¦»
    "aggressive_pricing",           # æ¿€è¿›å®šä»·
    "abnormal_large_order",         # å¼‚å¸¸å¤§å•
    "volatile_period_anomaly",      # å¼‚å¸¸æ—¶é—´æ®µæ´»åŠ¨
    "enhanced_spoofing_conservative", # ä¿å®ˆç‰ˆæ‰©å±•æ ‡ç­¾
    "enhanced_spoofing_moderate",     # ä¸­ç­‰ç‰ˆæ‰©å±•æ ‡ç­¾  
    "enhanced_spoofing_liberal",      # å®½æ¾ç‰ˆæ‰©å±•æ ‡ç­¾
    "enhanced_spoofing_strict",       # ä¸¥æ ¼ç‰ˆæ‰©å±•æ ‡ç­¾
    "enhanced_combined"               # ç»¼åˆæ ‡ç­¾
]

# è®­ç»ƒç”¨çš„æ ‡ç­¾åˆ—ï¼ˆä¸»è¦ç›®æ ‡å˜é‡ï¼‰
TRAINING_TARGET_COLUMNS = [
    "y_label",                        # åŸºç¡€æ ‡ç­¾
    "enhanced_spoofing_conservative", # ä¿å®ˆæ‰©å±•æ ‡ç­¾
    "enhanced_spoofing_moderate",     # ä¸­ç­‰æ‰©å±•æ ‡ç­¾
    "enhanced_combined"               # ç»¼åˆæ ‡ç­¾
]

# æ‰€æœ‰æ ‡ç­¾åˆ—
ALL_LABEL_COLUMNS = BASE_LABEL_COLUMNS + ENHANCED_LABEL_COLUMNS

# è¾“å‡ºæ—¶éœ€è¦ä¿å­˜çš„åˆ—ï¼ˆç”¨äºæ ‡ç­¾æ–‡ä»¶ï¼‰
LABEL_OUTPUT_COLUMNS = KEY_COLUMNS + TIME_COLUMNS + METADATA_COLUMNS + ALL_LABEL_COLUMNS

def get_label_columns(include_enhanced: bool = True) -> List[str]:
    """
    è·å–æ ‡ç­¾åˆ—åˆ—è¡¨
    
    Args:
        include_enhanced: æ˜¯å¦åŒ…å«æ‰©å±•æ ‡ç­¾
        
    Returns:
        æ ‡ç­¾åˆ—åˆ—è¡¨
    """
    if include_enhanced:
        return BASE_LABEL_COLUMNS + ENHANCED_LABEL_COLUMNS
    else:
        return BASE_LABEL_COLUMNS

def get_training_target_columns() -> List[str]:
    """è·å–å¯ç”¨äºè®­ç»ƒçš„ç›®æ ‡å˜é‡åˆ—è¡¨"""
    return TRAINING_TARGET_COLUMNS.copy()

def get_key_columns() -> List[str]:
    """è·å–ä¸»é”®åˆ—åˆ—è¡¨"""
    return KEY_COLUMNS.copy()

def get_metadata_columns() -> List[str]:
    """è·å–å…ƒæ•°æ®åˆ—åˆ—è¡¨"""
    return METADATA_COLUMNS.copy()

def get_time_columns() -> List[str]:
    """è·å–æ—¶é—´åˆ—åˆ—è¡¨"""
    return TIME_COLUMNS.copy()

def get_label_output_columns(include_enhanced: bool = True) -> List[str]:
    """
    è·å–æ ‡ç­¾æ–‡ä»¶è¾“å‡ºåˆ—åˆ—è¡¨
    
    Args:
        include_enhanced: æ˜¯å¦åŒ…å«æ‰©å±•æ ‡ç­¾
        
    Returns:
        è¾“å‡ºåˆ—åˆ—è¡¨
    """
    columns = KEY_COLUMNS + TIME_COLUMNS + METADATA_COLUMNS
    columns.extend(get_label_columns(include_enhanced))
    return columns

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ ‡ç­¾ç”Ÿæˆæ ¸å¿ƒå‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def apply_basic_spoofing_rules_pandas(df: pd.DataFrame, r1_ms: int, r2_ms: int, r2_mult: float) -> pd.DataFrame:
    """
    åŸºç¡€æ¬ºéª—æ ‡ç­¾è§„åˆ™ (Pandasç‰ˆæœ¬)
    
    Args:
        df: è¾“å…¥DataFrame
        r1_ms: R1è§„åˆ™æ—¶é—´é˜ˆå€¼(æ¯«ç§’)
        r2_ms: R2è§„åˆ™æ—¶é—´é˜ˆå€¼(æ¯«ç§’)
        r2_mult: R2è§„åˆ™ä»·å·®å€æ•°
        
    Returns:
        æ·»åŠ æ ‡ç­¾çš„DataFrame
    """
    try:
        # R1è§„åˆ™: å¿«é€Ÿæ’¤å•
        df['flag_R1'] = (df['å­˜æ´»æ—¶é—´_ms'] < r1_ms) & (df['äº‹ä»¶ç±»å‹'] == 'æ’¤å•')
        
        # R2è§„åˆ™: ä»·æ ¼æ“çºµ 
        if 'spread' in df.columns and 'delta_mid' in df.columns:
            safe_spread = df['spread'].fillna(np.inf).replace(0, np.inf)
            df['flag_R2'] = ((df['å­˜æ´»æ—¶é—´_ms'] < r2_ms) & 
                            (df['delta_mid'].abs() >= r2_mult * safe_spread))
            df['y_label'] = (df['flag_R1'] & df['flag_R2']).astype(int)
        else:
            df['flag_R2'] = False
            df['y_label'] = df['flag_R1'].astype(int)
            
        return df
        
    except Exception as e:
        console.print(f"[red]è­¦å‘Š: åŸºç¡€æ ‡ç­¾è§„åˆ™åº”ç”¨å¤±è´¥: {e}[/red]")
        if 'y_label' not in df.columns:
            df['y_label'] = 0
        return df

def apply_basic_spoofing_rules_polars(df: Union[pl.DataFrame, pl.LazyFrame], r1_ms: int, r2_ms: int, r2_mult: float) -> Union[pl.DataFrame, pl.LazyFrame]:
    """
    åŸºç¡€æ¬ºéª—æ ‡ç­¾è§„åˆ™ (Polarsç‰ˆæœ¬)
    
    Args:
        df: è¾“å…¥DataFrame/LazyFrame
        r1_ms: R1è§„åˆ™æ—¶é—´é˜ˆå€¼(æ¯«ç§’)
        r2_ms: R2è§„åˆ™æ—¶é—´é˜ˆå€¼(æ¯«ç§’) 
        r2_mult: R2è§„åˆ™ä»·å·®å€æ•°
        
    Returns:
        æ·»åŠ æ ‡ç­¾çš„DataFrame/LazyFrame
    """
    try:
        # è½¬æ¢ä¸ºLazyFrame
        if isinstance(df, pl.DataFrame):
            lazy_df = df.lazy()
            return_dataframe = True
        else:
            lazy_df = df
            return_dataframe = False
        
        # è·å–åˆ—å
        schema = lazy_df.schema
        
        # R1è§„åˆ™: å¿«é€Ÿæ’¤å•
        if all(col in schema for col in ['å­˜æ´»æ—¶é—´_ms', 'äº‹ä»¶ç±»å‹']):
            lazy_df = lazy_df.with_columns([
                ((pl.col('å­˜æ´»æ—¶é—´_ms') < r1_ms) & (pl.col('äº‹ä»¶ç±»å‹') == 'æ’¤å•')).alias('flag_R1')
            ])
        else:
            lazy_df = lazy_df.with_columns([pl.lit(False).alias('flag_R1')])
        
        # R2è§„åˆ™: ä»·æ ¼æ“çºµ
        if all(col in schema for col in ['å­˜æ´»æ—¶é—´_ms', 'spread', 'delta_mid']):
            safe_spread = pl.col('spread').fill_null(float('inf')).replace(0, float('inf'))
            lazy_df = lazy_df.with_columns([
                ((pl.col('å­˜æ´»æ—¶é—´_ms') < r2_ms) & 
                 (pl.col('delta_mid').abs() >= r2_mult * safe_spread)).alias('flag_R2')
            ])
            lazy_df = lazy_df.with_columns([
                (pl.col('flag_R1') & pl.col('flag_R2')).cast(pl.Int8).alias('y_label')
            ])
        else:
            lazy_df = lazy_df.with_columns([
                pl.lit(False).alias('flag_R2'),
                pl.col('flag_R1').cast(pl.Int8).alias('y_label')
            ])
        
        # è¿”å›åŸå§‹ç±»å‹
        if return_dataframe:
            return lazy_df.collect()
        else:
            return lazy_df
            
    except Exception as e:
        console.print(f"[red]è­¦å‘Š: Polarsæ ‡ç­¾è§„åˆ™åº”ç”¨å¤±è´¥: {e}[/red]")
        # å¦‚æœå¤±è´¥ï¼Œè¿”å›åŸå§‹æ•°æ®å¹¶æ·»åŠ åŸºæœ¬æ ‡ç­¾
        if isinstance(df, pl.DataFrame):
            return df.with_columns(pl.lit(0).cast(pl.Int8).alias('y_label'))
        else:
            return df.with_columns(pl.lit(0).cast(pl.Int8).alias('y_label'))

def apply_enhanced_spoofing_rules_pandas(df: pd.DataFrame, r1_ms: int, r2_ms: int, r2_mult: float) -> pd.DataFrame:
    """
    æ‰©å±•æ¬ºéª—æ ‡ç­¾è§„åˆ™ (Pandasç‰ˆæœ¬)
    
    Args:
        df: è¾“å…¥DataFrame
        r1_ms: R1è§„åˆ™æ—¶é—´é˜ˆå€¼(æ¯«ç§’)
        r2_ms: R2è§„åˆ™æ—¶é—´é˜ˆå€¼(æ¯«ç§’)
        r2_mult: R2è§„åˆ™ä»·å·®å€æ•°
        
    Returns:
        æ·»åŠ æ‰©å±•æ ‡ç­¾çš„DataFrame
    """
    try:
        # å…ˆåº”ç”¨åŸºç¡€è§„åˆ™
        df = apply_basic_spoofing_rules_pandas(df, r1_ms, r2_ms, r2_mult)
        
        # æ‰©å±•è§„åˆ™1: æç«¯ä»·æ ¼åç¦»
        if all(col in df.columns for col in ['å§”æ‰˜ä»·æ ¼', 'å§”æ‰˜æ•°é‡', 'ticker']):
            df['extreme_price_deviation'] = (
                (df['å§”æ‰˜æ•°é‡'] > df.groupby('ticker')['å§”æ‰˜æ•°é‡'].transform('quantile', 0.9))
            ).astype(int)
        else:
            df['extreme_price_deviation'] = 0
        
        # æ‰©å±•è§„åˆ™2: æ¿€è¿›å®šä»· (ä¿®å¤ï¼šåœ¨å¼€ç›˜æ—¶é—´æ®µæ›´ä¿å®ˆ)
        if all(col in df.columns for col in ['å§”æ‰˜ä»·æ ¼', 'bid1', 'ask1', 'æ–¹å‘_å§”æ‰˜', 'å§”æ‰˜_datetime']):
            df['å§”æ‰˜_datetime'] = pd.to_datetime(df['å§”æ‰˜_datetime'])
            
            # å¼€ç›˜æ—¶é—´æ®µ
            opening_periods = (
                ((df['å§”æ‰˜_datetime'].dt.time >= pd.to_datetime('09:30').time()) & 
                 (df['å§”æ‰˜_datetime'].dt.time <= pd.to_datetime('10:00').time())) |
                ((df['å§”æ‰˜_datetime'].dt.time >= pd.to_datetime('13:00').time()) & 
                 (df['å§”æ‰˜_datetime'].dt.time <= pd.to_datetime('13:15').time()))
            )
            
            # åŸºç¡€æ¿€è¿›å®šä»·
            basic_aggressive = (
                ((df['æ–¹å‘_å§”æ‰˜'] == 'ä¹°') & (df['å§”æ‰˜ä»·æ ¼'] > df['ask1'])) |
                ((df['æ–¹å‘_å§”æ‰˜'] == 'å–') & (df['å§”æ‰˜ä»·æ ¼'] < df['bid1']))
            )
            
            # å¼€ç›˜æ—¶é—´æ®µéœ€è¦æ›´æç«¯çš„ä»·æ ¼åç¦»æ‰æ ‡è®°
            spread = df['ask1'] - df['bid1']
            extreme_aggressive = (
                ((df['æ–¹å‘_å§”æ‰˜'] == 'ä¹°') & (df['å§”æ‰˜ä»·æ ¼'] > df['ask1'] + spread * 0.5)) |
                ((df['æ–¹å‘_å§”æ‰˜'] == 'å–') & (df['å§”æ‰˜ä»·æ ¼'] < df['bid1'] - spread * 0.5))
            )
            
            df['aggressive_pricing'] = (
                (opening_periods & extreme_aggressive) |  # å¼€ç›˜æ—¶éœ€è¦æç«¯åç¦»
                (~opening_periods & basic_aggressive)     # éå¼€ç›˜æ—¶æ­£å¸¸æ ‡å‡†
            ).astype(int)
        elif all(col in df.columns for col in ['å§”æ‰˜ä»·æ ¼', 'bid1', 'ask1', 'æ–¹å‘_å§”æ‰˜']):
            # é™çº§å¤„ç†ï¼šæ²¡æœ‰æ—¶é—´ä¿¡æ¯æ—¶ä½¿ç”¨åŸºç¡€é€»è¾‘
            df['aggressive_pricing'] = (
                (((df['æ–¹å‘_å§”æ‰˜'] == 'ä¹°') & (df['å§”æ‰˜ä»·æ ¼'] > df['ask1'])) |
                 ((df['æ–¹å‘_å§”æ‰˜'] == 'å–') & (df['å§”æ‰˜ä»·æ ¼'] < df['bid1'])))
            ).astype(int)
        else:
            df['aggressive_pricing'] = 0
        
        # æ‰©å±•è§„åˆ™3: å¼‚å¸¸å¤§å• (ä¿®å¤ï¼šæ’é™¤å¼€ç›˜æ—¶é—´æ®µçš„æ­£å¸¸å¤§å•)
        if all(col in df.columns for col in ['å§”æ‰˜æ•°é‡', 'ticker', 'å§”æ‰˜_datetime']):
            # è¯†åˆ«å¼€ç›˜æ—¶é—´æ®µï¼ˆæ­£å¸¸äº¤æ˜“æ´»è·ƒæœŸï¼‰
            df['å§”æ‰˜_datetime'] = pd.to_datetime(df['å§”æ‰˜_datetime']) 
            opening_periods = (
                # å¼€ç›˜å‰30åˆ†é’Ÿ
                ((df['å§”æ‰˜_datetime'].dt.time >= pd.to_datetime('09:30').time()) & 
                 (df['å§”æ‰˜_datetime'].dt.time <= pd.to_datetime('10:00').time())) |
                # åˆç›˜å¼€ç›˜å‰15åˆ†é’Ÿ  
                ((df['å§”æ‰˜_datetime'].dt.time >= pd.to_datetime('13:00').time()) & 
                 (df['å§”æ‰˜_datetime'].dt.time <= pd.to_datetime('13:15').time()))
            )
            
            # éå¼€ç›˜æ—¶é—´æ®µçš„å¼‚å¸¸å¤§å•æ‰æ ‡è®°
            df['abnormal_large_order'] = (
                (~opening_periods) &  # æ’é™¤å¼€ç›˜æ—¶é—´æ®µ
                (df['å§”æ‰˜æ•°é‡'] > df.groupby('ticker')['å§”æ‰˜æ•°é‡'].transform('quantile', 0.95))
            ).astype(int)
        elif all(col in df.columns for col in ['å§”æ‰˜æ•°é‡', 'ticker']):
            # é™çº§å¤„ç†ï¼šæ²¡æœ‰æ—¶é—´ä¿¡æ¯æ—¶ä½¿ç”¨æ›´é«˜é˜ˆå€¼
            df['abnormal_large_order'] = (
                df['å§”æ‰˜æ•°é‡'] > df.groupby('ticker')['å§”æ‰˜æ•°é‡'].transform('quantile', 0.98)
            ).astype(int)
        else:
            df['abnormal_large_order'] = 0
        
        # æ‰©å±•è§„åˆ™4: éæ­£å¸¸äº¤æ˜“æ—¶é—´å¼‚å¸¸æ´»åŠ¨ (ä¿®å¤ï¼šæ’é™¤æ­£å¸¸å¼€ç›˜æ”¶ç›˜æ—¶é—´)
        if 'å§”æ‰˜_datetime' in df.columns:
            df['å§”æ‰˜_datetime'] = pd.to_datetime(df['å§”æ‰˜_datetime'])
            # æ”¹ä¸ºæ£€æµ‹éæ­£å¸¸æ—¶é—´çš„å¼‚å¸¸æ´»åŠ¨
            # æ­£å¸¸äº¤æ˜“æ—¶é—´: 09:30-11:30, 13:00-15:00
            # å¼‚å¸¸æ—¶é—´: ç›˜å‰é›†åˆç«ä»·æ™šæœŸ 09:25-09:30, åˆä¼‘æ—¶é—´ç­‰
            abnormal_time = (
                # é›†åˆç«ä»·æ™šæœŸå¼‚å¸¸æ´»åŠ¨
                ((df['å§”æ‰˜_datetime'].dt.time >= pd.to_datetime('09:25').time()) & 
                 (df['å§”æ‰˜_datetime'].dt.time < pd.to_datetime('09:30').time())) |
                # åˆä¼‘æ—¶é—´å¼‚å¸¸æ´»åŠ¨  
                ((df['å§”æ‰˜_datetime'].dt.time >= pd.to_datetime('11:30').time()) & 
                 (df['å§”æ‰˜_datetime'].dt.time < pd.to_datetime('13:00').time()))
            )
            
            if 'å§”æ‰˜æ•°é‡' in df.columns and 'ticker' in df.columns:
                # åœ¨å¼‚å¸¸æ—¶é—´æ®µçš„å¤§å•æ‰æ ‡è®°ä¸ºå¯ç–‘
                df['volatile_period_anomaly'] = (
                    abnormal_time &
                    (df['å§”æ‰˜æ•°é‡'] > df.groupby('ticker')['å§”æ‰˜æ•°é‡'].transform('quantile', 0.9))
                ).astype(int)
            else:
                df['volatile_period_anomaly'] = 0
        else:
            df['volatile_period_anomaly'] = 0
        
        # ç»¼åˆæ‰©å±•æ ‡ç­¾ (ä¿®å¤ï¼šæ›´ä¿å®ˆçš„æ ‡ç­¾ç­–ç•¥)
        pattern_rules = ['extreme_price_deviation', 'aggressive_pricing', 'abnormal_large_order', 'volatile_period_anomaly']
        available_rules = [col for col in pattern_rules if col in df.columns]
        
        if available_rules:
            # ä¿å®ˆç‰ˆæœ¬ï¼šè‡³å°‘ä¸¤ä¸ªè§„åˆ™è§¦å‘ (é¿å…è¯¯æ ‡)
            df['enhanced_spoofing_conservative'] = (df[available_rules].sum(axis=1) >= 2).astype(int)
            # ä¸­ç­‰ç‰ˆæœ¬ï¼šå¤šä¸ªè§„åˆ™è§¦å‘
            df['enhanced_spoofing_moderate'] = (df[available_rules].sum(axis=1) >= 2).astype(int)
            # å®½æ¾ç‰ˆæœ¬ï¼šä»»æ„è§„åˆ™+åŸºç¡€è§„åˆ™ï¼Œæˆ–å¤šä¸ªè§„åˆ™
            if 'y_label' in df.columns:
                df['enhanced_spoofing_liberal'] = (
                    (df['y_label'] == 1) | (df[available_rules].sum(axis=1) >= 2)
                ).astype(int)
            else:
                df['enhanced_spoofing_liberal'] = (df[available_rules].sum(axis=1) >= 1).astype(int)
            
            # ä¸¥æ ¼ç‰ˆæœ¬ï¼šå¤§éƒ¨åˆ†è§„åˆ™è§¦å‘
            df['enhanced_spoofing_strict'] = (df[available_rules].sum(axis=1) >= 3).astype(int)
            
            # ç»“åˆåŸå§‹è§„åˆ™çš„ç»¼åˆæ ‡ç­¾ (æ›´ä¿å®ˆ)
            if 'y_label' in df.columns:
                df['enhanced_combined'] = (
                    (df['y_label'] == 1) | (df['enhanced_spoofing_conservative'] == 1)
                ).astype(int)
            else:
                df['enhanced_combined'] = df['enhanced_spoofing_conservative']
        
        return df
        
    except Exception as e:
        console.print(f"[red]è­¦å‘Š: æ‰©å±•æ ‡ç­¾è§„åˆ™åº”ç”¨å¤±è´¥: {e}[/red]")
        return df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ ‡ç­¾ç”Ÿæˆå™¨ç±» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class LabelGenerator:
    """æ ‡ç­¾ç”Ÿæˆå™¨"""
    
    def __init__(self, 
                 r1_ms: int = 50, 
                 r2_ms: int = 1000, 
                 r2_mult: float = 4.0,
                 extended_rules: bool = False,
                 backend: str = "polars"):
        """
        åˆå§‹åŒ–æ ‡ç­¾ç”Ÿæˆå™¨
        
        Args:
            r1_ms: R1è§„åˆ™æ—¶é—´é˜ˆå€¼(ms)
            r2_ms: R2è§„åˆ™æ—¶é—´é˜ˆå€¼(ms) 
            r2_mult: R2è§„åˆ™ä»·å·®å€æ•°
            extended_rules: æ˜¯å¦ä½¿ç”¨æ‰©å±•æ ‡ç­¾è§„åˆ™
            backend: è®¡ç®—åç«¯
        """
        self.r1_ms = r1_ms
        self.r2_ms = r2_ms
        self.r2_mult = r2_mult
        self.extended_rules = extended_rules
        self.backend = backend
        self.console = Console()
        
        # å®šä¹‰æ ‡ç­¾ç”Ÿæˆæµæ°´çº¿
        self.label_pipeline = self._build_label_pipeline()
    
    def _build_label_pipeline(self) -> List[dict]:
        """æ„å»ºæ ‡ç­¾ç”Ÿæˆæµæ°´çº¿"""
        if self.extended_rules:
            pipeline = [
                {
                    "name": "æ‰©å±•æ ‡ç­¾è§„åˆ™",
                    "function": "apply_enhanced_spoofing_rules",
                    "description": f"R1({self.r1_ms}ms) + R2({self.r2_ms}ms, {self.r2_mult}x) + æ‰©å±•è§„åˆ™"
                }
            ]
        else:
            pipeline = [
                {
                    "name": "åŸºç¡€æ ‡ç­¾è§„åˆ™", 
                    "function": "apply_basic_spoofing_rules",
                    "description": f"R1({self.r1_ms}ms) + R2({self.r2_ms}ms, {self.r2_mult}x)"
                }
            ]
        
        return pipeline
    
    def generate_labels_for_data(self,
                                data: Union[pd.DataFrame, pl.DataFrame, pl.LazyFrame],
                                tickers: Optional[Set[str]] = None,
                                show_progress: bool = True) -> Union[pd.DataFrame, pl.DataFrame]:
        """
        ä¸ºç»™å®šæ•°æ®ç”Ÿæˆæ ‡ç­¾
        
        Args:
            data: è¾“å…¥çš„å§”æ‰˜äº‹ä»¶æµæ•°æ®
            tickers: è‚¡ç¥¨ä»£ç ç­›é€‰
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            
        Returns:
            å¸¦æ ‡ç­¾çš„DataFrame
        """
        
        if show_progress:
            progress = Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                BarColumn(),
                console=self.console,
                transient=True
            )
            progress.start()
        
        try:
            # æ•°æ®é¢„å¤„ç†
            if show_progress:
                prep_task = progress.add_task("é¢„å¤„ç†æ•°æ®...", total=100)
            
            if self.backend == "polars":
                df_processed = self._preprocess_polars(data, tickers)
            else:
                df_processed = self._preprocess_pandas(data, tickers)
            
            if show_progress:
                progress.update(prep_task, advance=100)
            
            # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
            if self.backend == "polars":
                if isinstance(df_processed, pl.LazyFrame):
                    data_size = df_processed.collect().height
                else:
                    data_size = df_processed.height
            else:
                data_size = len(df_processed)
            
            if data_size == 0:
                self.console.print("[yellow]è­¦å‘Š: é¢„å¤„ç†åæ•°æ®ä¸ºç©º[/yellow]")
                return df_processed
            
            # æ ‡ç­¾ç”Ÿæˆæµæ°´çº¿
            for i, step in enumerate(self.label_pipeline):
                if show_progress:
                    label_task = progress.add_task(f"ç”Ÿæˆ{step['name']}...", total=100)
                
                try:
                    df_processed = self._execute_label_step(df_processed, step)
                    
                    if show_progress:
                        progress.update(label_task, advance=100)
                        
                except Exception as e:
                    self.console.print(f"[red]é”™è¯¯: {step['name']}ç”Ÿæˆå¤±è´¥: {e}[/red]")
                    if show_progress:
                        progress.update(label_task, advance=100)
                    continue
            
            return df_processed
            
        finally:
            if show_progress:
                progress.stop()
    
    def _preprocess_polars(self, data: Union[pl.DataFrame, pl.LazyFrame], tickers: Optional[Set[str]]) -> pl.LazyFrame:
        """Polarsæ•°æ®é¢„å¤„ç†"""
        if isinstance(data, pl.DataFrame):
            df = data.lazy()
        else:
            df = data
        
        # è‚¡ç¥¨ç­›é€‰
        if tickers:
            df = df.filter(pl.col("ticker").is_in(list(tickers)))
        
        # ç¡®ä¿æ—¶é—´åˆ—ç±»å‹æ­£ç¡®
        try:
            df = df.with_columns([
                pl.col("å§”æ‰˜_datetime").cast(pl.Datetime("ns")),
                pl.col("äº‹ä»¶_datetime").cast(pl.Datetime("ns"))
            ])
        except Exception as e:
            self.console.print(f"[yellow]è­¦å‘Š: æ—¶é—´åˆ—å¤„ç†å¤±è´¥: {e}[/yellow]")
        
        return df
    
    def _preprocess_pandas(self, data: pd.DataFrame, tickers: Optional[Set[str]]) -> pd.DataFrame:
        """Pandasæ•°æ®é¢„å¤„ç†"""
        df = data.copy()
        
        # è‚¡ç¥¨ç­›é€‰
        if tickers:
            df = df[df["ticker"].isin(tickers)]
        
        # ç¡®ä¿æ—¶é—´åˆ—ç±»å‹æ­£ç¡®
        try:
            df["å§”æ‰˜_datetime"] = pd.to_datetime(df["å§”æ‰˜_datetime"])
            df["äº‹ä»¶_datetime"] = pd.to_datetime(df["äº‹ä»¶_datetime"])
        except Exception as e:
            self.console.print(f"[yellow]è­¦å‘Š: æ—¶é—´åˆ—å¤„ç†å¤±è´¥: {e}[/yellow]")
        
        return df
    
    def _execute_label_step(self, data: Union[pd.DataFrame, pl.LazyFrame], step: dict) -> Union[pd.DataFrame, pl.LazyFrame]:
        """æ‰§è¡Œå•ä¸ªæ ‡ç­¾ç”Ÿæˆæ­¥éª¤"""
        func_name = step["function"]
        
        try:
            if func_name == "apply_basic_spoofing_rules":
                if self.backend == "polars":
                    return apply_basic_spoofing_rules_polars(
                        data, self.r1_ms, self.r2_ms, self.r2_mult
                    )
                else:
                    return apply_basic_spoofing_rules_pandas(
                        data, self.r1_ms, self.r2_ms, self.r2_mult
                    )
                    
            elif func_name == "apply_enhanced_spoofing_rules":
                if self.backend == "pandas":
                    return apply_enhanced_spoofing_rules_pandas(
                        data, self.r1_ms, self.r2_ms, self.r2_mult
                    )
                else:
                    # æ‰©å±•è§„åˆ™ç›®å‰åªæ”¯æŒpandasï¼Œéœ€è¦è½¬æ¢
                    if isinstance(data, pl.LazyFrame):
                        pd_data = data.collect().to_pandas()
                    else:
                        pd_data = data.to_pandas()
                    result = apply_enhanced_spoofing_rules_pandas(
                        pd_data, self.r1_ms, self.r2_ms, self.r2_mult
                    )
                    return pl.from_pandas(result)
            
            return data
            
        except Exception as e:
            self.console.print(f"[red]è­¦å‘Š: {step['name']}ç”Ÿæˆå¤±è´¥: {e}[/red]")
            return data
    
    def process_single_file(self,
                           input_path: Path,
                           output_path: Path,
                           tickers: Optional[Set[str]] = None) -> Dict:
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶
        
        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            tickers: è‚¡ç¥¨ä»£ç ç­›é€‰
            
        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        try:
            self.console.print(f"[cyan]ğŸ“ å¤„ç†æ–‡ä»¶: {input_path.name}[/cyan]")
            
            # åŠ è½½æ•°æ®
            if self.backend == "polars":
                df = pl.read_csv(input_path, try_parse_dates=True, infer_schema_length=10000, ignore_errors=True)
            else:
                df = pd.read_csv(input_path, parse_dates=["å§”æ‰˜_datetime", "äº‹ä»¶_datetime"], low_memory=False)
            
            # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
            if self.backend == "polars":
                if df.height == 0:
                    self.console.print(f"[yellow]è·³è¿‡ç©ºæ–‡ä»¶: {input_path.name}[/yellow]")
                    return {"success": False, "reason": "empty_file"}
            else:
                if len(df) == 0:
                    self.console.print(f"[yellow]è·³è¿‡ç©ºæ–‡ä»¶: {input_path.name}[/yellow]")
                    return {"success": False, "reason": "empty_file"}
            
            # ç”Ÿæˆæ ‡ç­¾
            df_labels = self.generate_labels_for_data(df, tickers=tickers)
            
            # ä½¿ç”¨æ˜ç¡®å®šä¹‰çš„åˆ—é€‰æ‹©ï¼ˆé¿å…å¯å‘å¼åˆ¤æ–­å‡ºé”™ï¼‰
            if self.backend == "polars":
                if isinstance(df_labels, pl.LazyFrame):
                    df_labels = df_labels.collect()
                
                # è·å–å®é™…å­˜åœ¨çš„è¾“å‡ºåˆ—
                available_cols = df_labels.columns
                final_cols = [col for col in get_label_output_columns(self.extended_rules) if col in available_cols]
                
                # ç¡®ä¿å…³é”®åˆ—å­˜åœ¨
                missing_key_cols = [col for col in KEY_COLUMNS if col not in available_cols]
                if missing_key_cols:
                    self.console.print(f"[yellow]è­¦å‘Š: ç¼ºå°‘å…³é”®åˆ— {missing_key_cols}[/yellow]")
                
                df_final = df_labels.select(final_cols)
                
                # ä¿å­˜ç»“æœ
                output_path.parent.mkdir(parents=True, exist_ok=True)
                df_final.write_parquet(output_path)
                
                # ç»Ÿè®¡ä¿¡æ¯
                total_samples = df_final.height
                positive_samples = 0
                if "y_label" in df_final.columns:
                    positive_samples = df_final["y_label"].sum()
                elif any("label" in col for col in df_final.columns):
                    label_col = next(col for col in df_final.columns if "label" in col)
                    positive_samples = df_final[label_col].sum()
                
            else:
                # Pandaså¤„ç†
                available_cols = df_labels.columns.tolist()
                final_cols = [col for col in get_label_output_columns(self.extended_rules) if col in available_cols]
                
                # ç¡®ä¿å…³é”®åˆ—å­˜åœ¨
                missing_key_cols = [col for col in KEY_COLUMNS if col not in available_cols]
                if missing_key_cols:
                    self.console.print(f"[yellow]è­¦å‘Š: ç¼ºå°‘å…³é”®åˆ— {missing_key_cols}[/yellow]")
                
                df_final = df_labels[final_cols]
                
                # ä¿å­˜ç»“æœ
                output_path.parent.mkdir(parents=True, exist_ok=True)
                df_final.to_parquet(output_path, index=False)
                
                # ç»Ÿè®¡ä¿¡æ¯
                total_samples = len(df_final)
                positive_samples = 0
                if "y_label" in df_final.columns:
                    positive_samples = df_final["y_label"].sum()
                elif any("label" in col for col in df_final.columns):
                    label_col = next(col for col in df_final.columns if "label" in col)
                    positive_samples = df_final[label_col].sum()
            
            self.console.print(f"[green]âœ“ å·²ä¿å­˜: {output_path.name}[/green]")
            self.console.print(f"  ğŸ“Š æ ·æœ¬æ•°: {total_samples:,}, æ­£æ ·æœ¬: {positive_samples}, æ¯”ä¾‹: {positive_samples/total_samples*100:.4f}%")
            
            return {
                "success": True,
                "total_samples": total_samples,
                "positive_samples": positive_samples,
                "positive_rate": positive_samples / total_samples if total_samples > 0 else 0
            }
            
        except Exception as e:
            self.console.print(f"[red]âŒ å¤„ç†å¤±è´¥ {input_path.name}: {e}[/red]")
            return {"success": False, "reason": str(e)}
    
    def get_summary(self) -> dict:
        """è·å–æ ‡ç­¾ç”Ÿæˆå™¨æ‘˜è¦ä¿¡æ¯"""
        return {
            "r1_ms": self.r1_ms,
            "r2_ms": self.r2_ms,
            "r2_mult": self.r2_mult,
            "extended_rules": self.extended_rules,
            "backend": self.backend,
            "pipeline_steps": len(self.label_pipeline),
            "pipeline_details": self.label_pipeline
        }

def process_event_stream_directory(event_stream_dir: Path,
                                  output_dir: Path,
                                  r1_ms: int = 50,
                                  r2_ms: int = 1000,
                                  r2_mult: float = 4.0,
                                  extended_rules: bool = False,
                                  backend: str = "polars",
                                  tickers: Optional[Set[str]] = None,
                                  dates: Optional[List[str]] = None) -> dict:
    """
    æ‰¹é‡å¤„ç†event_streamç›®å½•ä¸‹çš„æ‰€æœ‰æ—¥æœŸæ–‡ä»¶
    
    Args:
        event_stream_dir: event_streamæ ¹ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        r1_ms: R1è§„åˆ™æ—¶é—´é˜ˆå€¼
        r2_ms: R2è§„åˆ™æ—¶é—´é˜ˆå€¼
        r2_mult: R2è§„åˆ™ä»·å·®å€æ•°
        extended_rules: æ˜¯å¦ä½¿ç”¨æ‰©å±•æ ‡ç­¾è§„åˆ™
        backend: è®¡ç®—åç«¯
        tickers: è‚¡ç¥¨ä»£ç ç­›é€‰
        dates: æŒ‡å®šå¤„ç†æ—¥æœŸ
        
    Returns:
        å¤„ç†ç»“æœç»Ÿè®¡
    """
    
    # åˆ›å»ºæ ‡ç­¾ç”Ÿæˆå™¨
    generator = LabelGenerator(
        r1_ms=r1_ms, r2_ms=r2_ms, r2_mult=r2_mult,
        extended_rules=extended_rules, backend=backend
    )
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    summary = generator.get_summary()
    console.print(f"\n[bold green]ğŸ·ï¸ æ ‡ç­¾ç”Ÿæˆæ¨¡å—[/bold green]")
    console.print(f"[dim]è¾“å…¥ç›®å½•: {event_stream_dir}[/dim]")
    console.print(f"[dim]è¾“å‡ºç›®å½•: {output_dir}[/dim]")
    console.print(f"[dim]è®¡ç®—åç«¯: {summary['backend']}[/dim]")
    console.print(f"[dim]R1é˜ˆå€¼: {summary['r1_ms']}ms[/dim]")
    console.print(f"[dim]R2é˜ˆå€¼: {summary['r2_ms']}ms (Ã—{summary['r2_mult']})[/dim]")
    console.print(f"[dim]æ‰©å±•è§„åˆ™: {summary['extended_rules']}[/dim]")
    console.print(f"[dim]è‚¡ç¥¨ç­›é€‰: {list(tickers) if tickers else 'å…¨éƒ¨'}[/dim]")
    
    for step in summary['pipeline_details']:
        console.print(f"[dim]  â€¢ {step['name']}: {step['description']}[/dim]")
    
    # æŸ¥æ‰¾æ‰€æœ‰å§”æ‰˜äº‹ä»¶æµæ–‡ä»¶
    csv_files = list(event_stream_dir.glob("*/å§”æ‰˜äº‹ä»¶æµ.csv"))
    
    if not csv_files:
        console.print(f"[red]é”™è¯¯: æœªæ‰¾åˆ°å§”æ‰˜äº‹ä»¶æµæ–‡ä»¶ {event_stream_dir}[/red]")
        return {"total": 0, "success": 0, "failed": 0}
    
    # æ—¥æœŸç­›é€‰
    if dates:
        target_dates = set(dates)
        csv_files = [f for f in csv_files if f.parent.name in target_dates]
        missing_dates = target_dates - {f.parent.name for f in csv_files}
        if missing_dates:
            console.print(f"[yellow]è­¦å‘Š: æœªæ‰¾åˆ°æ—¥æœŸ {missing_dates}[/yellow]")
    
    if not csv_files:
        console.print(f"[red]é”™è¯¯: ç­›é€‰åæ— å¯å¤„ç†æ–‡ä»¶[/red]")
        return {"total": 0, "success": 0, "failed": 0}
    
    console.print(f"[dim]å‘ç° {len(csv_files)} ä¸ªæ–‡ä»¶å¾…å¤„ç†[/dim]\n")
    
    # æ‰¹é‡å¤„ç†
    results = {
        "total": len(csv_files), "success": 0, "failed": 0,
        "processed_files": [], "total_samples": 0, "total_positives": 0
    }
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeElapsedColumn(),
        console=console
    ) as progress:
        task = progress.add_task("å¤„ç†æ–‡ä»¶", total=len(csv_files))
        
        for csv_file in sorted(csv_files):
            date_str = csv_file.parent.name
            output_file = output_dir / f"labels_{date_str}.parquet"
            
            progress.update(task, description=f"å¤„ç† {date_str}")
            
            result = generator.process_single_file(csv_file, output_file, tickers)
            
            if result["success"]:
                results["success"] += 1
                results["processed_files"].append(date_str)
                results["total_samples"] += result.get("total_samples", 0)
                results["total_positives"] += result.get("positive_samples", 0)
            else:
                results["failed"] += 1
            
            progress.advance(task)
    
    return results

def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description="æ ‡ç­¾ç”Ÿæˆæ¨¡å—")
    parser.add_argument("--input_dir", required=True, help="event_streamæ ¹ç›®å½•")
    parser.add_argument("--output_dir", required=True, help="æ ‡ç­¾è¾“å‡ºç›®å½•")
    parser.add_argument("--r1_ms", type=int, default=50, help="R1è§„åˆ™æ—¶é—´é˜ˆå€¼(ms)")
    parser.add_argument("--r2_ms", type=int, default=1000, help="R2è§„åˆ™æ—¶é—´é˜ˆå€¼(ms)")
    parser.add_argument("--r2_mult", type=float, default=4.0, help="R2è§„åˆ™ä»·å·®å€æ•°")
    parser.add_argument("--extended", action="store_true", help="ä½¿ç”¨æ‰©å±•æ ‡ç­¾è§„åˆ™")
    parser.add_argument("--backend", choices=["pandas", "polars"], default="polars", help="è®¡ç®—åç«¯")
    parser.add_argument("--tickers", nargs="*", help="è‚¡ç¥¨ä»£ç ç­›é€‰")
    parser.add_argument("--dates", nargs="*", help="æŒ‡å®šå¤„ç†æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDD")
    
    args = parser.parse_args()
    
    # éªŒè¯è¾“å…¥ç›®å½•
    input_dir = Path(args.input_dir)
    if not input_dir.exists():
        console.print(f"[red]é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨ {input_dir}[/red]")
        sys.exit(1)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # å¤„ç†å‚æ•°
    tickers_set = set(args.tickers) if args.tickers else None
    
    try:
        # æ‰§è¡Œæ‰¹é‡å¤„ç†
        results = process_event_stream_directory(
            event_stream_dir=input_dir,
            output_dir=output_dir,
            r1_ms=args.r1_ms,
            r2_ms=args.r2_ms,
            r2_mult=args.r2_mult,
            extended_rules=args.extended,
            backend=args.backend,
            tickers=tickers_set,
            dates=args.dates
        )
        
        # æ˜¾ç¤ºç»“æœ
        console.print(f"\n[bold cyan]ğŸ“Š å¤„ç†å®Œæˆ[/bold cyan]")
        console.print(f"æ€»æ–‡ä»¶æ•°: {results['total']}")
        console.print(f"æˆåŠŸ: {results['success']}")
        console.print(f"å¤±è´¥: {results['failed']}")
        
        if results['success'] > 0:
            console.print(f"[green]âœ… æ ‡ç­¾æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_dir}[/green]")
            console.print(f"å¤„ç†æ—¥æœŸ: {sorted(results['processed_files'])}")
            console.print(f"æ€»æ ·æœ¬æ•°: {results['total_samples']:,}")
            console.print(f"æ­£æ ·æœ¬æ•°: {results['total_positives']:,}")
            if results['total_samples'] > 0:
                positive_rate = results['total_positives'] / results['total_samples']
                console.print(f"æ•´ä½“æ­£æ ·æœ¬æ¯”ä¾‹: {positive_rate*100:.4f}%")
        
        if results['failed'] > 0:
            console.print(f"[red]âš ï¸ {results['failed']} ä¸ªæ–‡ä»¶å¤„ç†å¤±è´¥[/red]")
        
    except Exception as e:
        console.print(f"[red]âŒ å¤„ç†å‡ºé”™: {e}[/red]")
        sys.exit(1)

if __name__ == "__main__":
    main()

"""
ä½¿ç”¨ç¤ºä¾‹:

# åŸºç¡€æ ‡ç­¾ç”Ÿæˆ (æ¨èä½¿ç”¨polarsåç«¯)
python scripts/data_process/labels/label_generator.py \
    --input_dir "/home/ma-user/code/fenglang/Spoofing Detect/data/event_stream" \
    --output_dir "/home/ma-user/code/fenglang/Spoofing Detect/data/labels" \
    --r1_ms 50 --r2_ms 1000 --r2_mult 4.0 \
    --backend polars

# å®é™…ä½¿ç”¨ï¼šæ‰©å±•æ ‡ç­¾è§„åˆ™ (åŒ…å«æ›´å¤šæ¬ºè¯ˆæ£€æµ‹æ¨¡å¼)
python scripts/data_process/labels/label_generator.py \
    --input_dir "/home/ma-user/code/fenglang/Spoofing Detect/data/event_stream" \
    --output_dir "/home/ma-user/code/fenglang/Spoofing Detect/data/labels_enhanced" \
    --r1_ms 1000 --r2_ms 1000 --r2_mult 1.0 \
    --tickers 300233.SZ \
    --extended \
    --backend polars

# æŒ‡å®šè‚¡ç¥¨å’Œæ—¥æœŸ
python scripts/data_process/labels/label_generator.py \
    --input_dir "/home/ma-user/code/fenglang/Spoofing Detect/data/event_stream" \
    --output_dir "/home/ma-user/code/fenglang/Spoofing Detect/data/labels" \
    --tickers 000001.SZ 000002.SZ \
    --dates 20240301 20240302 \
    --backend polars

# æ‰¹é‡å¤„ç†æ‰€æœ‰æ•°æ®
python scripts/data_process/labels/label_generator.py \
    --input_dir "/home/ma-user/code/fenglang/Spoofing Detect/data/event_stream" \
    --output_dir "/home/ma-user/code/fenglang/Spoofing Detect/data/labels" \
    --backend polars
""" 