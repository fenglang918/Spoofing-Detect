#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Improved Labeling for Spoofing Detection
----------------------------------------
æ”¹è¿›çš„æ ‡ç­¾å®šä¹‰ç­–ç•¥ï¼š
â€¢ æ›´ç»†è‡´çš„spoofingæ¨¡å¼è¯†åˆ«
â€¢ å¤šå±‚æ¬¡æ ‡ç­¾ï¼šå¿«é€Ÿæ’¤å•ã€ä»·æ ¼æ“çºµã€è®¢å•å †ç§¯ç­‰
â€¢ è€ƒè™‘å¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾
â€¢ å‡å°‘å‡é˜³æ€§ï¼Œæé«˜æ ‡ç­¾è´¨é‡
"""

import pandas as pd
import numpy as np
from pathlib import Path
import argparse
import warnings
warnings.filterwarnings('ignore')

def calculate_order_book_pressure(df):
    """è®¡ç®—è®¢å•ç°¿å‹åŠ›æŒ‡æ ‡"""
    try:
        # æ£€æŸ¥å¿…éœ€çš„åˆ—æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨æ›¿ä»£æ–¹æ¡ˆ
        if 'ç”³ä¹°é‡1' in df.columns and 'ç”³å–é‡1' in df.columns:
            # ä¹°å–å‹åŠ›ä¸å¹³è¡¡
            df['book_imbalance'] = (df['ç”³ä¹°é‡1'] - df['ç”³å–é‡1']) / (df['ç”³ä¹°é‡1'] + df['ç”³å–é‡1'] + 1e-8)
        else:
            # å¦‚æœæ²¡æœ‰ç”³ä¹°é‡ç”³å–é‡ï¼Œä½¿ç”¨ç®€åŒ–æŒ‡æ ‡
            df['book_imbalance'] = 0.0
            print("  âš ï¸ Missing ç”³ä¹°é‡1/ç”³å–é‡1 columns, using simplified book_imbalance")
        
        # ä»·æ ¼åç¦»åº¦ - éœ€è¦æ£€æŸ¥å¿…è¦çš„åˆ—
        required_cols = ['å§”æ‰˜ä»·æ ¼', 'bid1', 'ask1', 'is_buy']
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            print(f"  âš ï¸ Missing columns for price_aggressiveness: {missing_cols}")
            df['price_aggressiveness'] = 0.0
        else:
            # éœ€è¦è®¡ç®—spread
            if 'spread' not in df.columns:
                df['spread'] = df['ask1'] - df['bid1']
            
            df['price_aggressiveness'] = np.where(
                df['is_buy'] == 1,
                (df['å§”æ‰˜ä»·æ ¼'] - df['bid1']) / (df['spread'] + 1e-8),
                (df['ask1'] - df['å§”æ‰˜ä»·æ ¼']) / (df['spread'] + 1e-8)
            )
    except Exception as e:
        print(f"  âš ï¸ Error in calculate_order_book_pressure: {e}")
        # è®¾ç½®é»˜è®¤å€¼
        df['book_imbalance'] = 0.0
        df['price_aggressiveness'] = 0.0
    
    return df

def detect_layering_pattern(group_df):
    """æ£€æµ‹åˆ†å±‚ä¸‹å•æ¨¡å¼ï¼ˆLayeringï¼‰"""
    try:
        # æ£€æŸ¥å¿…éœ€çš„åˆ—
        required_cols = ['å§”æ‰˜_datetime', 'æ–¹å‘_å§”æ‰˜', 'å§”æ‰˜ä»·æ ¼', 'å§”æ‰˜æ•°é‡', 'is_buy']
        missing_cols = [col for col in required_cols if col not in group_df.columns]
        
        if missing_cols:
            print(f"    âš ï¸ Missing columns for layering detection: {missing_cols}")
            group_df['layering_score'] = 0
            return group_df
        
        # æŒ‰å§”æ‰˜æ—¶é—´æ’åº
        group_df = group_df.sort_values('å§”æ‰˜_datetime')
        
        # æ£€æµ‹çŸ­æ—¶é—´å†…å¤§é‡åŒæ–¹å‘è®¢å•
        layering_signals = []
        
        for i, row in group_df.iterrows():
            # æ£€æŸ¥å‰å1ç§’å†…çš„è®¢å•
            time_window = pd.Timedelta('1s')
            start_time = row['å§”æ‰˜_datetime'] - time_window
            end_time = row['å§”æ‰˜_datetime'] + time_window
            
            nearby_orders = group_df[
                (group_df['å§”æ‰˜_datetime'] >= start_time) & 
                (group_df['å§”æ‰˜_datetime'] <= end_time) &
                (group_df['æ–¹å‘_å§”æ‰˜'] == row['æ–¹å‘_å§”æ‰˜'])
            ]
            
            # åˆ†å±‚ç‰¹å¾ï¼šå¤šä¸ªå°è®¢å•ï¼Œä»·æ ¼é€’å¢/é€’å‡
            if len(nearby_orders) >= 3:
                prices = nearby_orders['å§”æ‰˜ä»·æ ¼'].values
                quantities = nearby_orders['å§”æ‰˜æ•°é‡'].values
                
                # æ£€æŸ¥ä»·æ ¼æ˜¯å¦æœ‰åºåˆ—æ€§
                if row['is_buy'] == 1:
                    price_ordered = np.all(np.diff(prices) >= 0)  # ä¹°å•ä»·æ ¼é€’å¢
                else:
                    price_ordered = np.all(np.diff(prices) <= 0)  # å–å•ä»·æ ¼é€’å‡
                
                # æ£€æŸ¥è®¢å•å¤§å°æ˜¯å¦ç›¸å¯¹è¾ƒå°ä¸”ç›¸ä¼¼
                qty_small = np.mean(quantities) < np.percentile(group_df['å§”æ‰˜æ•°é‡'], 50)
                qty_similar = np.std(quantities) / (np.mean(quantities) + 1e-8) < 0.5
                
                layering_score = int(price_ordered and qty_small and qty_similar)
            else:
                layering_score = 0
                
            layering_signals.append(layering_score)
        
        group_df['layering_score'] = layering_signals
    except Exception as e:
        print(f"    âš ï¸ Error in layering detection: {e}")
        group_df['layering_score'] = 0
    
    return group_df

def improved_spoofing_rules(df):
    """æ”¹è¿›çš„æ¬ºè¯ˆæ£€æµ‹è§„åˆ™"""
    labels = {}
    
    try:
        # æ£€æŸ¥å¿…éœ€çš„åˆ—å¹¶è®¾ç½®é»˜è®¤å€¼
        if 'at_bid' not in df.columns:
            df['at_bid'] = 0
        if 'at_ask' not in df.columns:
            df['at_ask'] = 0
        if 'price_aggressiveness' not in df.columns:
            df['price_aggressiveness'] = 0.0
        if 'layering_score' not in df.columns:
            df['layering_score'] = 0
            
        # Rule 1: å¿«é€Ÿæ’¤å• + å¸‚åœºå½±å“
        if all(col in df.columns for col in ['å­˜æ´»æ—¶é—´_ms', 'äº‹ä»¶ç±»å‹', 'å§”æ‰˜æ•°é‡']):
            conditions_r1 = [
                df['å­˜æ´»æ—¶é—´_ms'] < 100,  # å¿«é€Ÿæ’¤å•
                df['äº‹ä»¶ç±»å‹'] == 'æ’¤å•',
                (df['at_bid'] == 1) | (df['at_ask'] == 1),  # åœ¨æœ€ä¼˜ä»·ä½
                df['å§”æ‰˜æ•°é‡'] > df.groupby('ticker')['å§”æ‰˜æ•°é‡'].transform('median') * 2  # è®¢å•è¾ƒå¤§
            ]
            labels['quick_cancel_impact'] = np.all(conditions_r1, axis=0).astype(int)
        else:
            labels['quick_cancel_impact'] = np.zeros(len(df), dtype=int)
        
        # Rule 2: ä»·æ ¼æ“çºµæ¨¡å¼
        if all(col in df.columns for col in ['å­˜æ´»æ—¶é—´_ms', 'äº‹ä»¶ç±»å‹', 'å§”æ‰˜æ•°é‡']):
            conditions_r2 = [
                df['å­˜æ´»æ—¶é—´_ms'] < 500,
                df['äº‹ä»¶ç±»å‹'] == 'æ’¤å•',
                np.abs(df['price_aggressiveness']) > 2.0,  # ä»·æ ¼è¿‡äºæ¿€è¿›
                df['å§”æ‰˜æ•°é‡'] > df.groupby('ticker')['å§”æ‰˜æ•°é‡'].transform('quantile', 0.75)
            ]
            labels['price_manipulation'] = np.all(conditions_r2, axis=0).astype(int)
        else:
            labels['price_manipulation'] = np.zeros(len(df), dtype=int)
        
        # Rule 3: è™šå‡æµåŠ¨æ€§æä¾›
        if all(col in df.columns for col in ['å­˜æ´»æ—¶é—´_ms', 'äº‹ä»¶ç±»å‹', 'å§”æ‰˜ä»·æ ¼', 'bid1', 'ask1', 'å§”æ‰˜æ•°é‡']):
            conditions_r3 = [
                df['å­˜æ´»æ—¶é—´_ms'] < 200,
                df['äº‹ä»¶ç±»å‹'] == 'æ’¤å•',
                ((df['å§”æ‰˜ä»·æ ¼'] == df['bid1']) | (df['å§”æ‰˜ä»·æ ¼'] == df['ask1'])),
                df['å§”æ‰˜æ•°é‡'] > df.groupby('ticker')['å§”æ‰˜æ•°é‡'].transform('quantile', 0.9)
            ]
            labels['fake_liquidity'] = np.all(conditions_r3, axis=0).astype(int)
        else:
            labels['fake_liquidity'] = np.zeros(len(df), dtype=int)
        
        # Rule 4: è®¢å•å †ç§¯åæ’¤å•
        if all(col in df.columns for col in ['å­˜æ´»æ—¶é—´_ms', 'äº‹ä»¶ç±»å‹']):
            conditions_r4 = [
                df['layering_score'] > 0,
                df['å­˜æ´»æ—¶é—´_ms'] < 1000,
                df['äº‹ä»¶ç±»å‹'] == 'æ’¤å•'
            ]
            labels['layering_cancel'] = np.all(conditions_r4, axis=0).astype(int)
        else:
            labels['layering_cancel'] = np.zeros(len(df), dtype=int)
        
        # Rule 5: å¼‚å¸¸æ—¶é—´æ¨¡å¼
        if all(col in df.columns for col in ['å§”æ‰˜_datetime', 'å­˜æ´»æ—¶é—´_ms', 'äº‹ä»¶ç±»å‹', 'å§”æ‰˜æ•°é‡']):
            market_active_hours = (
                (df['å§”æ‰˜_datetime'].dt.time >= pd.to_datetime('09:30').time()) &
                (df['å§”æ‰˜_datetime'].dt.time <= pd.to_datetime('10:30').time())
            ) | (
                (df['å§”æ‰˜_datetime'].dt.time >= pd.to_datetime('14:00').time()) &
                (df['å§”æ‰˜_datetime'].dt.time <= pd.to_datetime('15:00').time())
            )
            
            conditions_r5 = [
                df['å­˜æ´»æ—¶é—´_ms'] < 50,
                df['äº‹ä»¶ç±»å‹'] == 'æ’¤å•',
                market_active_hours,
                df['å§”æ‰˜æ•°é‡'] > df.groupby('ticker')['å§”æ‰˜æ•°é‡'].transform('median')
            ]
            labels['active_hours_spoofing'] = np.all(conditions_r5, axis=0).astype(int)
        else:
            labels['active_hours_spoofing'] = np.zeros(len(df), dtype=int)
        
        # ç»¼åˆæ ‡ç­¾ï¼šä»»ä½•ä¸€ç§æ¨¡å¼è§¦å‘
        labels['composite_spoofing'] = (
            labels['quick_cancel_impact'] |
            labels['price_manipulation'] | 
            labels['fake_liquidity'] |
            labels['layering_cancel'] |
            labels['active_hours_spoofing']
        ).astype(int)
        
        # ä¿å®ˆæ ‡ç­¾ï¼šå¤šç§æ¨¡å¼åŒæ—¶è§¦å‘
        labels['conservative_spoofing'] = (
            (labels['quick_cancel_impact'] + 
             labels['price_manipulation'] + 
             labels['fake_liquidity'] + 
             labels['layering_cancel'] + 
             labels['active_hours_spoofing']) >= 2
        ).astype(int)
        
    except Exception as e:
        print(f"  âš ï¸ Error in improved_spoofing_rules: {e}")
        # è®¾ç½®æ‰€æœ‰æ ‡ç­¾ä¸º0
        n_rows = len(df)
        for label_name in ['quick_cancel_impact', 'price_manipulation', 'fake_liquidity', 
                          'layering_cancel', 'active_hours_spoofing', 'composite_spoofing', 'conservative_spoofing']:
            labels[label_name] = np.zeros(n_rows, dtype=int)
    
    return pd.DataFrame(labels)

def process_enhanced_labels(df):
    """å¤„ç†å¢å¼ºæ ‡ç­¾"""
    print("ğŸ·ï¸ Creating enhanced spoofing labels...")
    
    # 1. è®¡ç®—è®¢å•ç°¿å‹åŠ›æŒ‡æ ‡
    df = calculate_order_book_pressure(df)
    
    # 2. æŒ‰è‚¡ç¥¨å’Œæ—¥æœŸåˆ†ç»„å¤„ç†åˆ†å±‚æ£€æµ‹
    enhanced_groups = []
    for (ticker, date), group in df.groupby(['ticker', 'è‡ªç„¶æ—¥']):
        print(f"  Processing {ticker} on {date}...")
        group_enhanced = detect_layering_pattern(group)
        enhanced_groups.append(group_enhanced)
    
    df_enhanced = pd.concat(enhanced_groups, ignore_index=True)
    
    # 3. åº”ç”¨æ”¹è¿›çš„æ¬ºè¯ˆè§„åˆ™
    label_df = improved_spoofing_rules(df_enhanced)
    
    # 4. åˆå¹¶æ ‡ç­¾
    final_df = pd.concat([df_enhanced, label_df], axis=1)
    
    return final_df

def analyze_label_quality(df):
    """åˆ†ææ ‡ç­¾è´¨é‡"""
    print("\nğŸ“Š Label Quality Analysis:")
    
    label_cols = [col for col in df.columns if 'spoofing' in col or col.startswith('quick_') 
                  or col.startswith('price_') or col.startswith('fake_') 
                  or col.startswith('layering_') or col.startswith('active_')]
    
    for col in label_cols:
        if col in df.columns:
            pos_count = df[col].sum()
            pos_rate = pos_count / len(df) * 100
            print(f"  {col}: {pos_count:,} ({pos_rate:.4f}%)")
    
    # æ ‡ç­¾ç›¸å…³æ€§åˆ†æ
    if len(label_cols) > 1:
        label_corr = df[label_cols].corr()
        print(f"\nğŸ“ˆ Label Correlations:")
        print(label_corr.round(3))

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_root", required=True, help="æ•°æ®æ ¹ç›®å½•")
    parser.add_argument("--input_pattern", default="event_stream/*/å§”æ‰˜äº‹ä»¶æµ.csv", 
                       help="è¾“å…¥æ–‡ä»¶æ¨¡å¼")
    parser.add_argument("--output_dir", default="enhanced_labels", 
                       help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    input_root = Path(args.data_root)
    output_root = input_root / args.output_dir
    output_root.mkdir(exist_ok=True)
    
    # æŸ¥æ‰¾æ‰€æœ‰äº‹ä»¶æµæ–‡ä»¶
    import glob
    pattern = str(input_root / args.input_pattern)
    event_files = glob.glob(pattern)
    
    if not event_files:
        print(f"âŒ No files found matching: {pattern}")
        return
    
    print(f"ğŸ” Found {len(event_files)} event stream files")
    
    total_orders = 0
    total_spoofing = 0
    
    for event_file in sorted(event_files):
        date_str = Path(event_file).parent.name
        print(f"\nğŸ“… Processing {date_str}...")
        
        try:
            # è¯»å–äº‹ä»¶æµæ•°æ®
            df = pd.read_csv(event_file, parse_dates=['å§”æ‰˜_datetime', 'äº‹ä»¶_datetime'])
            
            if df.empty:
                print(f"  âš ï¸ Empty file: {date_str}")
                continue
            
            # å¤„ç†å¢å¼ºæ ‡ç­¾
            df_enhanced = process_enhanced_labels(df)
            
            # åˆ†ææ ‡ç­¾è´¨é‡
            analyze_label_quality(df_enhanced)
            
            # ä¿å­˜å¢å¼ºæ ‡ç­¾æ•°æ®
            output_file = output_root / f"enhanced_labels_{date_str}.parquet"
            df_enhanced.to_parquet(output_file, index=False)
            
            # ç»Ÿè®¡
            orders_count = len(df_enhanced)
            spoofing_count = df_enhanced.get('composite_spoofing', pd.Series([0])).sum()
            
            total_orders += orders_count
            total_spoofing += spoofing_count
            
            print(f"  âœ… Saved {orders_count:,} orders, {spoofing_count} spoofing cases")
            
        except Exception as e:
            print(f"  âŒ Error processing {date_str}: {e}")
            continue
    
    print(f"\nğŸ¯ Summary:")
    print(f"  Total orders: {total_orders:,}")
    print(f"  Total spoofing: {total_spoofing:,}")
    if total_orders > 0:
        print(f"  Spoofing rate: {total_spoofing/total_orders*100:.4f}%")

if __name__ == "__main__":
    main()

"""
# ä½¿ç”¨ç¤ºä¾‹
python scripts/data_process/improved_labeling.py \
    --data_root "/obs/users/fenglang/general/Spoofing Detect/data" \
    --input_pattern "event_stream/*/å§”æ‰˜äº‹ä»¶æµ.csv" \
    --output_dir "enhanced_labels"
""" 